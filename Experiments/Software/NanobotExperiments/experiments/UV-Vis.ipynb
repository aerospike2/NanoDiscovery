{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import find_peaks, peak_widths,peak_prominences\n",
    "import bisect\n",
    "import time \n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(wavelengths,intensities,fc=15):\n",
    "    \"\"\"\n",
    "    Use a low pass filter to deal with the read_in data.\n",
    "    Args:\n",
    "        wavelengths: the input wavelength.\n",
    "        intensities: the corresponding intensities of UV-Vis.\n",
    "        fc: frequency of low pass filter.\n",
    "    Returns:\n",
    "        series: the intensities passing through the low-pass filter.\n",
    "    \"\"\"\n",
    "    fs = wavelengths.shape[0]  # Sampling frequency\n",
    "    w = fc / (fs / 2) # Normalize the frequency\n",
    "    b, a = signal.butter(5, w, 'low')\n",
    "    series = signal.filtfilt(b, a, intensities)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_prominence(x,a=1,b=70,c=0.4,d=100,e=1,f=0.1,threshold=0.05):\n",
    "    \"\"\"\n",
    "    Definte a function which is more sensitive when x is small.\n",
    "    Args:\n",
    "        x: the peak prominence to be processed by this function.\n",
    "        a,b,c,d,e,f: constant the tune the shape of this function.\n",
    "        threshold: the threshold from where this function begin to behave like a linear function.\n",
    "    Returns:\n",
    "        The processed peak prominence after this function, which will be further used to calculate the scores.\n",
    "    \"\"\"\n",
    "    if x<threshold:\n",
    "        return (np.tanh((x-threshold)*d)+e)*f\n",
    "    else:\n",
    "        return (a*x+c*(1/(1+np.exp(-b*x))-0.5))/(a+c*(1/(1+np.exp(-b))-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_binary(x,b=100,threshold=0.05):\n",
    "    \"\"\"\n",
    "    Use a tanh function to binarize peaks accoridng to its promiencen.\n",
    "    Args:\n",
    "        x: the peak prominence to be processed by this function.\n",
    "        b: a variable to tune the shape of this function.\n",
    "        threshold: the threshold after which the function behave like a linear function.\n",
    "    Returns:\n",
    "        the processed peak prominence.\n",
    "    \"\"\"\n",
    "    return (np.tanh((x-threshold)*b)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizedata(series_original):\n",
    "    \"\"\"\n",
    "    Definte a function which normalize the input data into range (0,1).\n",
    "        \n",
    "    \"\"\"\n",
    "    return (series_original-np.min(series_original))/(np.max(series_original)-np.min(series_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_smoothness(x):\n",
    "    \"\"\"\n",
    "    Calculate the smootheness of the spectrum. \n",
    "    The smoothness is defined byy the absolute difference between the original spectrum and the spectrum after low-pass filter.\n",
    "    Args:\n",
    "        x: the UV-Vis spectrum\n",
    "    Returns:\n",
    "        The quantity measuring the smootheness of this spectrum.\n",
    "    \"\"\"\n",
    "    return np.std(np.diff(x))/abs(np.mean(np.diff(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_UV_Vis(base_sample,index,lower=400,upper=950,fc=15,color=\"red\",plot_flag=True,normalize=False):\n",
    "    #Read in json file\n",
    "    with open(base_sample+f\"00%02d/uv.json\"%(index)) as json_data:\n",
    "        d = json.load(json_data)\n",
    "        #read wavelength and intensities\n",
    "        wavelengths = np.array(d['wavelength'])\n",
    "        series_original = np.array(d['absorbances'])\n",
    "    #trim data\n",
    "    series_original = series_original[(wavelengths>lower) & (wavelengths < upper)]\n",
    "    wavelengths = wavelengths[(wavelengths>lower) & (wavelengths < upper)]\n",
    "    #trim data in the range of lower to upper\n",
    "    series_original=normalizedata(series_original[(wavelengths>lower) & (wavelengths < upper)])\n",
    "    series=low_pass_filter(wavelengths,series_original,fc=fc)\n",
    "    roughness=abs(series-series_original).mean()\n",
    "    \n",
    "    series=normalizedata(series)\n",
    "    \n",
    "    if plot_flag and normalize==True:\n",
    "        plt.plot(wavelengths,series,c=\"black\")\n",
    "        plt.plot(wavelengths,series_original,c=color)\n",
    "    \n",
    "    UV_inter = interp1d(wavelengths, series, kind='cubic',fill_value='extrapolate' )\n",
    "    return UV_inter,roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1D(region,boundary,roughness,series,peaks,prominences,wavelengths):    \n",
    "    #plot part\n",
    "    plt.figure()\n",
    "        \n",
    "    plt.plot(wavelengths,series)\n",
    "    plt.plot(wavelengths[peaks], series[peaks], \"x\")\n",
    "    plt.vlines(boundary, ymin=0, ymax=1,color=\"r\",linestyles =\"dashed\")\n",
    "    for region_temp in region:\n",
    "        plt.vlines(region, ymin=0, ymax=1,color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_scores(base_sample,index,boundary1,boundary2,near_width=50,lower=400,upper=950,num=101,False_width=10000,plot_flag=True):\n",
    "    \"\"\"\n",
    "    Calculate the defined UV-Vis scores of a sample.\n",
    "    Args:\n",
    "        base_sample: the directory of the sample\n",
    "        index: the index of the sample\n",
    "        boundary1: the boundaries to diecretize the UV-Vis region for one peak system\n",
    "        boundary2: the boundaries to discretize the UV-Vis spectrum for two peak system\n",
    "        near_width: the width to define the nearby region\n",
    "        lower: the lower wavelength boundary of UV-Vis\n",
    "        upper: the upper wavelength boundary of UV-Vis\n",
    "        num: the sampling number in wavelength [lower,upper]\n",
    "        False_width: the width this function returns when there's no peak in the system\n",
    "    Returns:\n",
    "        \n",
    "   \"\"\"\n",
    "    UV_sample,roughness=read_in_UV_Vis(base_sample,index,plot_flag=plot_flag)\n",
    "\n",
    "    #define the wavelength and got the UV-Vis spectrum\n",
    "    wavelengths=np.linspace(lower,upper,num)\n",
    "\n",
    "    series=UV_sample(wavelengths)\n",
    "\n",
    "    #find peaks in the data\n",
    "    peaks, _ = find_peaks(series,prominence=0.02)\n",
    "    if len(peaks) == 0:\n",
    "        print(\"None peaks are found!\")\n",
    "        plt.close()\n",
    "        return []\n",
    "    #find prominence of individual peaks\n",
    "    prominences,left_basis,right_basis = peak_prominences(series, peaks)\n",
    "    results_half = peak_widths(series, peaks, rel_height=0.5)\n",
    "    results_full = peak_widths(series, peaks, rel_height=1)\n",
    "    \n",
    "    # if the peak number are larger than 2\n",
    "    if len(prominences) >=2 :\n",
    "        #obtain the largest two peaks\n",
    "        peak_index = prominences.argsort()[-2:][::-1]\n",
    "        left_basis = left_basis[peak_index]\n",
    "        right_basis = right_basis[peak_index]\n",
    "        \n",
    "        peak_position1 = wavelengths[peaks[peak_index[0]]]\n",
    "        peak_position2 = wavelengths[peaks[peak_index[1]]]\n",
    "        \n",
    "        #judge the grid this sample belongs to \n",
    "        peak_class1 = bisect.bisect_left(boundary2, peak_position1)\n",
    "        peak_class2 = bisect.bisect_left(boundary2, peak_position2)\n",
    "        sample_class_index = [peak_class1,peak_class2]\n",
    "        \n",
    "        # get the prominence compared to left and right side\n",
    "        prominence_left = np.array([series[peaks[peak_index[i]]] - series[left_basis[i]] for i in range(2)])\n",
    "        prominence_right = np.array([series[peaks[peak_index[i]]] - series[right_basis[i]] for i in range(2)])\n",
    "        \n",
    "        #obtian the original domain\n",
    "        region = [[peak_position1-near_width,peak_position1+near_width],\n",
    "                  [peak_position2-near_width,peak_position2+near_width]]\n",
    "                \n",
    "        #select the domain for the highest peak\n",
    "        region1 = [[peak_position1-near_width,peak_position1+near_width]]\n",
    "        region2 = [[peak_position2-near_width,peak_position2+near_width]]\n",
    "        \n",
    "        # get wirdth\n",
    "        width1 = results_half[0][peak_index[0]].item()*(wavelengths[1]-wavelengths[0])\n",
    "        width2 = results_half[0][peak_index[1]].item()*(wavelengths[1]-wavelengths[0])\n",
    "        \n",
    "#         print(results_half[0][peak_index[0]].item()*(wavelengths[1]-wavelengths[0]))\n",
    "#         print(results_half[0][peak_index[1]].item()*(wavelengths[1]-wavelengths[0]))\n",
    "        \n",
    "        # no amplification\n",
    "        width1_amp = width1*1\n",
    "        width2_amp = width2*1\n",
    "        \n",
    "        background1 = series[peaks[peak_index[0]]] - prominences[0]\n",
    "        background2 = series[peaks[peak_index[1]]] - prominences[1]\n",
    "        \n",
    "        #calculate the absorption band for two absorption bands and record as scrore1 \n",
    "        #calculate the absorption band for the absorption band defined by more prominent peak and record as score2\n",
    "        absorption_band=0\n",
    "        for i in range(len(region)):\n",
    "            region_temp = region[i]\n",
    "            absorption_band = absorption_band + series[(wavelengths > region_temp[0]) & (wavelengths < region_temp[1])].sum()\n",
    "            \n",
    "        score2 = series[(wavelengths > region1[0][0]) & (wavelengths < region1[0][1])].sum()  \n",
    "        score2 = score2/series.sum()\n",
    "        score4 = series[(wavelengths > region2[0][0]) & (wavelengths < region2[0][1])].sum()\n",
    "        score4 = score4/series.sum()\n",
    "        \n",
    "\n",
    "    if len(prominences) >=2:\n",
    "        if plot_flag:\n",
    "            #plot the absorption domains\n",
    "            plot_1D(region,boundary2,roughness,series,peaks,prominences,wavelengths)\n",
    "            #plot the absorption domains\n",
    "            contour_heights = series[peaks] - prominences\n",
    "            if len(results_half[0])>0:\n",
    "                plt.scatter(wavelengths[_['left_bases']],series[_['left_bases']],c='black')\n",
    "                plt.scatter(wavelengths[_['right_bases']],series[_['right_bases']],c='black')\n",
    "                plt.vlines(x=wavelengths[peaks], ymin=contour_heights, ymax=series[peaks])\n",
    "                plt.hlines(*(results_half[1],wavelengths[np.around(results_half[2]).astype(\"int\")],wavelengths[np.around(results_half[3]).astype(\"int\")]), color=\"C2\")\n",
    "                plt.hlines(*(results_full[1],wavelengths[np.around(results_full[2]).astype(\"int\")],wavelengths[np.around(results_full[3]).astype(\"int\")]), color=\"C3\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(wavelengths,series,c=\"black\")\n",
    "            plt.fill_between(wavelengths,series, color='blue', \n",
    "                 alpha=0.5) \n",
    "            for region_temp in region:\n",
    "                plt.fill_between(wavelengths[(wavelengths>region_temp[0]) & (wavelengths<region_temp[1])],series[(wavelengths>region_temp[0]) & (wavelengths<region_temp[1])], color=\"blue\", \n",
    "                                 alpha=0.5) \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "    #return the results\n",
    "    if len(prominences) >=2 :\n",
    "        return np.array([2,\n",
    "                         [score2,score4],\n",
    "                         [width1,width2],\n",
    "                         [width1_amp,width2_amp],\n",
    "                         [background1,background2],\n",
    "                         sample_class_index,\n",
    "                         roughness,\n",
    "                         prominences.max()])\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process UV-Vis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for generation_num in range(10):\n",
    "    base_sample=f\"../data/custom/MAP_elite_generation_{generation_num}/\"\n",
    "    while True:\n",
    "        if pathlib.Path(base_sample+'/flag2.txt').is_file():\n",
    "            break\n",
    "        time.sleep(2)\n",
    "    data_output_total=[]\n",
    "    pHs = []\n",
    "    for i in range(24):\n",
    "        plt.plot()\n",
    "        print(generation_num,i)\n",
    "        data_output=obtain_scores(base_sample,\n",
    "                              i,\n",
    "                              boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                              boundary2=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                              near_width=50,\n",
    "                              lower=400,\n",
    "                              upper=950,\n",
    "                              num=1101,\n",
    "                              False_width=10000)\n",
    "        data_output_total.append(data_output)\n",
    "        if len(data_output)>0:\n",
    "            if data_output[0] == 2:\n",
    "                print(-0.002*(data_output[3][0] + data_output[3][1])+abs(data_output[1][0] - data_output[1][1]))\n",
    "                print(-0.002*(data_output[3][0] + data_output[3][1])-abs(data_output[1][0] - data_output[1][1]))\n",
    "                print(data_output[-3])\n",
    "                print(data_output)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        with open(base_sample+'%04d'%i+\"/pH_operation.json\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "    #         print(data[f\"{len(data)-1}\"][-1])\n",
    "        pHs.append(data[f\"{len(data)-1}\"][-2])\n",
    "        with open(base_sample+'%04d'%i+\"/params.json\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "            print(data)\n",
    "    np.save(base_sample+\"data_total\",data_output_total)\n",
    "    np.save(base_sample+\"pHs\",pHs)\n",
    "    \n",
    "    # After process the data, record the flag so that algorithim can generate new experiments\n",
    "    with open(base_sample+'/flag3.txt', 'w') as f:\n",
    "        json.dump(1, f,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool=[]\n",
    "total_generations = 10\n",
    "for generation_num in range(total_generations):\n",
    "    base_directory=\"../data/custom/\"\n",
    "    path=base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption%d.npz\"%generation_num\n",
    "    pool_temp = np.load(path,allow_pickle=True)[\"arr_0\"]\n",
    "    pool.append(pool_temp[pool_temp[:,-1].argsort()])\n",
    "plt.xlabel(\"batch number\")\n",
    "plt.ylabel(\"elite number\")\n",
    "plt.scatter(np.arange(len(pool)),np.array([len(pool_temp) for pool_temp in pool]),c = \"black\")\n",
    "plt.plot(np.array([len(pool_temp) for pool_temp in pool]),c = \"black\")\n",
    "\n",
    "fitness_total = []\n",
    "for grid_index in range(len(pool[-1][:,-1])):\n",
    "    fitness_temp = []\n",
    "    for generation_num in range(total_generations):\n",
    "        fitness_temp.append((pool[generation_num][pool[generation_num][:,-1] == pool[-1][:,-1][grid_index]])[:,-2])\n",
    "    for index_temp in range(len(fitness_temp)):\n",
    "        if len(fitness_temp[index_temp]) == 0:\n",
    "            fitness_temp[index_temp] = None\n",
    "    fitness_total.append(fitness_temp)\n",
    "best_grids = np.unique(pool[-1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for grid_index in range(len(pool[-1][:,-1])):\n",
    "    print(fitness_total[grid_index])\n",
    "    if fitness_total[grid_index][-2] != None:\n",
    "        print(fitness_total[grid_index][-1] - fitness_total[grid_index][-2])\n",
    "    plt.scatter(np.arange(len(fitness_total[grid_index])),fitness_total[grid_index])\n",
    "    plt.plot(np.arange(len(fitness_total[grid_index])),fitness_total[grid_index])\n",
    "    \n",
    "plt.xlabel(\"generation\")\n",
    "plt.ylabel(\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
