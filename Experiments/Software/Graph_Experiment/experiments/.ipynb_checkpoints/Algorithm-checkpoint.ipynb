{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_directory=\"../data/custom/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def obtain_random_samples(feature_num,initial_num=10):\n",
    "    \"\"\"\n",
    "    Generate random uniformly distributed initial samples\n",
    "    Args:\n",
    "        feature_num: number of features\n",
    "        initial_num: number of initial samples\n",
    "    Returns:\n",
    "        X: randomly generated samples\n",
    "    \"\"\"\n",
    "    X_initial=np.random.uniform(size=(initial_num,feature_num-1))\n",
    "    X_temp=np.sort(np.hstack((np.hstack((np.zeros((X_initial.shape[0],1)),X_initial)),np.ones((X_initial.shape[0],1)))))\n",
    "    X=np.diff(X_temp,axis=-1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def obtain_constrained_random_samples(feature_num,constrain=1,initial_num=10):\n",
    "    \"\"\"\n",
    "    Generate random uniformly distributed initial samples with a linear constrain\n",
    "    Args:\n",
    "        feature_num: number of features\n",
    "        initial_num: number of initial samples\n",
    "    Returns:\n",
    "        X: randomly generated samples\n",
    "    \"\"\"\n",
    "    X = np.empty((0,feature_num))\n",
    "    while len(X) < initial_num:\n",
    "        X_temp = np.random.uniform(0,1,(1,feature_num))\n",
    "        if X_temp.sum() <= constrain:\n",
    "            X = np.append(X,X_temp,axis=0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def cross_over(pool_absorption,pool_absorption_pH,feature_num):\n",
    "    \"\"\"\n",
    "    Cross-over based on the pool of absorption\n",
    "    Args:\n",
    "        pool_absorption: the pool of high absoprtion performance\n",
    "        feature_num: the number of sample features\n",
    "    Returns:\n",
    "        offspring: the offspring after crossover\n",
    "    \"\"\"\n",
    "    pool=np.array(pool_absorption)[:,0:feature_num]\n",
    "    pool_pH = np.array(pool_absorption_pH)\n",
    "    index=np.random.choice(len(pool),size=2,replace=True)\n",
    "    offspring=np.zeros((1,feature_num))\n",
    "    offspring_pH = np.zeros((1,1))\n",
    "    for i in range(feature_num):\n",
    "        offspring[0,i]=pool[index[np.random.randint(2)]][i]\n",
    "    offspring_pH[0,0] = pool_pH[index[np.random.randint(2)]]\n",
    "    print(\"crossover\")\n",
    "    print(index)\n",
    "    print(offspring,offspring_pH)\n",
    "    return offspring,offspring_pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mutation(offspring,mutate_rate,sigma,constrain=1):\n",
    "    \"\"\"\n",
    "    Mutate the genotype of the offsprings\n",
    "    Args:\n",
    "        offspring: the offspring to be evaluated\n",
    "        mutate_rate: the probability of mutation\n",
    "    Returns:\n",
    "        mutated_offspring: the mutated offspring\n",
    "        mutation_flag: the flag indicating if mutation happened\n",
    "    \"\"\"\n",
    "    offspring=offspring.reshape(1,-1)\n",
    "    # keeping tracing the numerical error and get rid of possible numerical error\n",
    "    if offspring.sum() > constrain:\n",
    "        offspring = offspring/offspring.sum()\n",
    "        \n",
    "    solutions=[]\n",
    "    if np.random.random() < mutate_rate:\n",
    "        mutation_direction = np.random.normal(0,sigma,offspring.shape)\n",
    "        offspring_direct = offspring + mutation_direction\n",
    "        # after direct mutation, check if all the constrains are satisfied\n",
    "        # if not, calculate the minimum distance we can add with this mutation direction\n",
    "        if offspring_direct.sum()>constrain:\n",
    "            solutions.append((constrain-offspring.sum())/mutation_direction.sum())\n",
    "        index = np.where(offspring_direct<0)\n",
    "        for x in range(len(index[0])):\n",
    "            solutions.append((0-offspring[index[0][x],index[1][x]])/mutation_direction[index[0][x],index[1][x]])\n",
    "        solutions = np.array(solutions)\n",
    "        # sometimes because of numerical error, the minimum quantity is not 0 but smaller than zero\n",
    "        # the absolute value is small enough but we still want to see it\n",
    "        if (np.array(solutions)<0).sum()>0:\n",
    "            print(\"warning:mutation_direction changed in mutation!\")\n",
    "            print(solutions)\n",
    "        # get rid of the numerical error mentioned above by setting it to 0\n",
    "        solutions[solutions<1e-10] = 0\n",
    "        \n",
    "        if len(solutions)>0: # return the mutation result under absoprtion boundary condition\n",
    "            return offspring+np.min(solutions)*mutation_direction,True\n",
    "        else: # return the mutation result without hitting any boundary\n",
    "            return offspring+mutation_direction,True\n",
    "    else:\n",
    "        return offspring,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_offspring(feature_num,pool_absorption,pool_absorption_pH,mutation_rate,sigma,batch_size):\n",
    "    \"\"\"\n",
    "    Generate the next set of experiments according to the current observation\n",
    "    Args:\n",
    "        feature_num: the number of sample features\n",
    "        pool_absorption: the pool recording the information of maximized absorption band: \n",
    "                        [feature,performance,index of attribute]\n",
    "        mutation_rate: the rate for mutation\n",
    "        sigma: the standard deviation of mutation\n",
    "        batch_size: the experiment number for every generation\n",
    "    Returns:\n",
    "        offspring: the generated offspring\n",
    "    \"\"\"\n",
    "    # performance cross_over+mutation\n",
    "    offspring=np.empty((0,feature_num))\n",
    "    offspring_pH = np.empty((0,1))\n",
    "    \n",
    "    while len(offspring)<batch_size/2:\n",
    "        # performance crossover and normalize it to be within the range\n",
    "        offspring_temp_original,offspring_pH_temp_original=cross_over(pool_absorption,pool_absorption_pH,feature_num)\n",
    "        \n",
    "        # normalize the groups respectively\n",
    "        if offspring_temp_original[:,0:2].sum()>1:\n",
    "            offspring_temp_original[:,0:2] = offspring_temp_original[:,0:2]/offspring_temp_original[:,0:2].sum()\n",
    "        if offspring_temp_original[:,2:4].sum()>1:\n",
    "            offspring_temp_original[:,2:4] = offspring_temp_original[:,2:4]/offspring_temp_original[:,2:4].sum()\n",
    "        # performance mutation and the probabilit of getting mutated is mutation_rate\n",
    "        # if it's near the boundary, the mutation chance would be small because of the limitation of the boundary\n",
    "        offspring_temp1,mutation_flag1 = mutation(offspring_temp_original[:,0:2],mutation_rate,sigma)\n",
    "        offspring_temp2,mutation_flag2 = mutation(offspring_temp_original[:,2:4],mutation_rate,sigma)\n",
    "        # mutate the pH variable\n",
    "        offspring_pH_temp,mutation_flag_pH =  mutation(offspring_pH_temp_original,mutation_rate,sigma)\n",
    "        print(offspring_temp1,mutation_flag1)\n",
    "        print(offspring_temp2,mutation_flag2)\n",
    "        print(offspring_pH_temp,mutation_flag_pH)\n",
    "        # we need to correct the numerical error after mutation when the float point is smaller than 0\n",
    "        offspring_temp1[offspring_temp1<0] = 0\n",
    "        offspring_temp2[offspring_temp2<0] = 0\n",
    "        offspring_pH_temp[offspring_pH_temp<0] = 0\n",
    "        \n",
    "        # performance a validate mutation if we decide to mutate so it's different from the original one\n",
    "        # it's to get rid of the trapping problem in the boundary\n",
    "        while (mutation_flag1 == True) and ((abs(offspring_temp1 - offspring_temp_original[:,0:2])<1e-10).sum() == 2):\n",
    "            offspring_temp1,mutation_flag1=mutation(offspring_temp_original[:,0:2],1,sigma)\n",
    "            # correct the numerical error after mutation\n",
    "            offspring_temp1[offspring_temp1<0] = 0\n",
    "                \n",
    "        # performance a validate mutation if we decide to mutate so it's different from the original one\n",
    "        # it's to get rid of the trapping problem in the boundary\n",
    "        while (mutation_flag2 == True) and ((abs(offspring_temp2 - offspring_temp_original[:,2:4])<1e-10).sum() == 2):\n",
    "            offspring_temp2,mutation_flag2=mutation(offspring_temp_original[:,2:4],1,sigma)\n",
    "            # correct the numerical error after mutation\n",
    "            offspring_temp2[offspring_temp2<0] = 0  \n",
    "                \n",
    "        # do the same thing for the mutation of pH\n",
    "        while (mutation_flag_pH == True) and ((abs(offspring_pH_temp - offspring_pH_temp_original)<1e-10).sum() == 1):\n",
    "            offspring_pH_temp,mutation_flag_pH =  mutation(offspring_pH_temp_original,1,sigma)\n",
    "            # check point, if the negative value is too large, there's an error\n",
    "            if sum(abs(offspring_pH_temp[offspring_pH_temp<0])>1e-5)>0:\n",
    "                print(\"Error! The negative value is too large!\")\n",
    "                print(offspring_pH_temp)\n",
    "            # correct the numerical error after mutation\n",
    "            offspring_pH_temp[offspring_pH_temp<0] = 0\n",
    "            if mutation_flag_pH == False:\n",
    "                print(\"Error in crossover for pH control!\")        \n",
    "            \n",
    "        # due to numerical error, it's acceptable. But the difference shouldn't be to much\n",
    "        if offspring_temp1.sum(axis=1)>1:\n",
    "            print(\"In mutation, the summation is larger than 1!\")\n",
    "            print(\"Mutation flag: {}\".format(mutation_flag1))\n",
    "            print(offspring_temp1.sum())\n",
    "            offspring_temp1=offspring_temp1/offspring_temp1.sum()\n",
    "            print(offspring_temp1.sum())\n",
    "            \n",
    "        # due to numerical error, it's acceptable. But the difference shouldn't be to much\n",
    "        if offspring_temp2.sum(axis=1)>1:\n",
    "            print(\"In mutation, the summation is larger than 1!\")\n",
    "            print(\"Mutation flag: {}\".format(mutation_flag2))\n",
    "            print(offspring_temp2.sum())\n",
    "            offspring_temp2=offspring_temp2/offspring_temp2.sum()\n",
    "            print(offspring_temp2.sum())\n",
    "            \n",
    "        # do the same thing to the pH variable\n",
    "        if offspring_pH_temp.sum(axis=1)>1:\n",
    "            print(\"In crossover, the pH variable is larger than 1!\")\n",
    "            print(\"Mutation flag: {}\".format(mutation_flag_pH))\n",
    "            print(offspring_pH_temp.sum())\n",
    "            offspring_pH_temp=offspring_pH_temp/offspring_pH_temp.sum()\n",
    "            print(offspring_pH_temp.sum()) \n",
    "            \n",
    "        offspring_temp = np.hstack((offspring_temp1,offspring_temp2))\n",
    "        print(\"final output is\")\n",
    "        print(offspring_temp)\n",
    "        # if there's already a sample with exactly the same experimental condition and pH here, pass\n",
    "        if offspring_temp.flatten().tolist() in offspring.tolist() and offspring_pH_temp.flatten().tolist() in offspring_pH.tolist():\n",
    "            position1 = np.where(np.all(offspring == offspring_temp,axis=1))[0][0]\n",
    "            position2 = np.where(np.all(offspring_pH == offspring_pH_temp,axis=1))[0][0]\n",
    "            if position1 == position2:\n",
    "                pass\n",
    "            else:\n",
    "                offspring=np.append(offspring,offspring_temp,axis=0)\n",
    "                offspring_pH = np.append(offspring_pH,offspring_pH_temp,axis=0)\n",
    "        else:\n",
    "            offspring=np.append(offspring,offspring_temp,axis=0)\n",
    "            offspring_pH = np.append(offspring_pH,offspring_pH_temp,axis=0)\n",
    "        \n",
    "    # performance pure mutation\n",
    "    pool=np.array(pool_absorption)[:,0:feature_num]\n",
    "    pool_pH = np.array(pool_absorption_pH)\n",
    "    \n",
    "    while len(offspring)<batch_size:\n",
    "        # randomly select one sample for mutation\n",
    "        index=np.random.choice(len(pool),size=1).item()\n",
    "        print(\"mutation\")\n",
    "        print(index)\n",
    "        print(pool[index][0:2],pool[index][2:4],pool_pH[index])\n",
    "        offspring_temp1,mutation_flag1=mutation(pool[index][0:2],1,sigma)\n",
    "        offspring_temp2,mutation_flag2=mutation(pool[index][2:4],1,sigma)\n",
    "        offspring_pH_temp,mutation_flag=mutation(pool_pH[index],1,sigma)\n",
    "        print(offspring_temp1,mutation_flag1, offspring_temp2,mutation_flag2,offspring_pH_temp,mutation_flag)\n",
    "        \n",
    "        offspring_temp1[offspring_temp1<0] = 0\n",
    "        offspring_temp2[offspring_temp2<0] = 0\n",
    "        offspring_pH_temp[offspring_pH_temp<0] = 0\n",
    "        \n",
    "        # get rid of the problem when it's in the boundary, \n",
    "        # it has the probabilit of being trapped and didn't really get changed.\n",
    "        while ((abs(offspring_temp1 - pool[index][0:2])<1e-10).sum() == 2):\n",
    "            offspring_temp1,mutation_flag1 = mutation(pool[index][0:2],1,sigma)\n",
    "            offspring_temp1[offspring_temp1<0] = 0 \n",
    "            \n",
    "        while ((abs(offspring_temp2 - pool[index][2:4])<1e-10).sum() == 2):\n",
    "            offspring_temp2,mutation_flag2 = mutation(pool[index][2:4],1,sigma)     \n",
    "            offspring_temp2[offspring_temp2<0] = 0\n",
    "            \n",
    "        # the same thing can happen to the pH variable:\n",
    "        while ((abs(offspring_pH_temp - pool_pH[index])<1e-10).sum() == 1):\n",
    "            offspring_pH_temp,mutation_flag = mutation(pool_pH[index],1,sigma)\n",
    "            offspring_pH_temp[offspring_pH_temp<0] = 0\n",
    "        \n",
    "        # due to numerical error, it's acceptable. But the difference shouldn't be to much\n",
    "        if offspring_temp1.sum(axis=1)>1:\n",
    "            offspring_temp1=offspring_temp1/offspring_temp1.sum()\n",
    "            \n",
    "        # due to numerical error, it's acceptable. But the difference shouldn't be to much\n",
    "        if offspring_temp2.sum(axis=1)>1:\n",
    "            offspring_temp2=offspring_temp2/offspring_temp2.sum()\n",
    "            \n",
    "        # apply the same rule to pH variable\n",
    "        if offspring_pH_temp.sum(axis=1)>1:\n",
    "            offspring_pH_temp=offspring_pH_temp/offspring_pH_temp.sum()        \n",
    "            \n",
    "        offspring_temp = np.hstack((offspring_temp1,offspring_temp2)) \n",
    "        \n",
    "        # if there's already a sample with exactly the same experimental condition and pH here, pass\n",
    "        if offspring_temp.flatten().tolist() in offspring.tolist() and offspring_pH_temp.flatten().tolist() in offspring_pH.tolist():\n",
    "            position1 = np.where(np.all(offspring == offspring_temp,axis=1))[0][0]\n",
    "            position2 = np.where(np.all(offspring_pH == offspring_pH_temp,axis=1))[0][0]\n",
    "            if position1 == position2:\n",
    "                pass\n",
    "            else:\n",
    "                offspring=np.append(offspring,offspring_temp,axis=0)\n",
    "                offspring_pH = np.append(offspring_pH,offspring_pH_temp,axis=0)\n",
    "        else:\n",
    "            offspring=np.append(offspring,offspring_temp,axis=0)\n",
    "            offspring_pH = np.append(offspring_pH,offspring_pH_temp,axis=0)\n",
    "        \n",
    "    return offspring,offspring_pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def update_pool(offspring,offspring_pH,offspring_performance,offspring_index,pool_absorption,pool_absorption_pH):\n",
    "    \"\"\"\n",
    "    Update the current pool with MAP-elite algorithm\n",
    "    Args:\n",
    "        offspring: the offspring \n",
    "        offspring_performance: the main performance from the offspring\n",
    "        offspring_index: the interested attributes from the offspring\n",
    "        pool_absorption: the current pool of samples with high absorption\n",
    "    Returns:\n",
    "        pool_absorption: the updated pool of samples with high absorption\n",
    "    \"\"\"\n",
    "    index=offspring_index\n",
    "    \n",
    "    for attribute_index in np.unique(index):\n",
    "        performance_temp=offspring_performance[index==attribute_index]\n",
    "        offspring_pH_temp = offspring_pH[index==attribute_index]\n",
    "        offspring_temp=offspring[index==attribute_index]\n",
    "        sample_1_index=np.argmax(performance_temp[:,0])\n",
    "        sample_1=np.concatenate((offspring_temp[sample_1_index],\n",
    "                                 performance_temp[sample_1_index],\n",
    "                                 [attribute_index]))\n",
    "        \n",
    "        if len(pool_absorption[pool_absorption[:,-1]==attribute_index])==0:\n",
    "            pool_absorption=np.vstack((pool_absorption,sample_1))\n",
    "            pool_absorption_pH=np.vstack((pool_absorption_pH,offspring_pH_temp[sample_1_index]))\n",
    "            \n",
    "        elif pool_absorption[pool_absorption[:,-1]==attribute_index][0,feature_num]<sample_1[feature_num]:\n",
    "            pool_absorption[pool_absorption[:,-1]==attribute_index]=sample_1.reshape(1,-1)\n",
    "            pool_absorption_pH[pool_absorption[:,-1]==attribute_index]=offspring_pH_temp[sample_1_index].reshape(1,-1)\n",
    "            \n",
    "    return pool_absorption,pool_absorption_pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_reagent_volume(X,Ranges,V_total=11.5):\n",
    "    X_new=np.zeros((X.shape))\n",
    "    for i in range(len(Ranges)):\n",
    "        X_new[:,i]=X[:,i]*(Ranges[i][1]-Ranges[i][0])+Ranges[i][0]\n",
    "    X_new=np.around(X_new,2)\n",
    "    X_final=np.hstack((X_new,V_total-X_new.sum(axis=1).reshape(-1,1)))\n",
    "    return np.around(X_final,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_json_file_for_Nanobot(X1,X2,X_pH,Ranges1,Ranges2,pH_Range,V_total1,V_total2,generation_num,random_sampling_size=3):\n",
    "    #write out the volume of algorithm X\n",
    "    if generation_num==0:\n",
    "        pass\n",
    "    else:\n",
    "        X_temp=obtain_constrained_random_samples(feature_num=2,initial_num=random_sampling_size)\n",
    "        X1=np.vstack((X1,X_temp))\n",
    "        \n",
    "        X_temp=obtain_constrained_random_samples(feature_num=2,initial_num=random_sampling_size)\n",
    "        X2=np.vstack((X2,X_temp))\n",
    "        \n",
    "        X_pH_temp = obtain_constrained_random_samples(feature_num = 1,initial_num=random_sampling_size) \n",
    "        X_pH = np.vstack((X_pH,X_pH_temp))\n",
    "        \n",
    "    reagents1=create_reagent_volume(X1,Ranges1,V_total1)\n",
    "    reagents2=create_reagent_volume(X2,Ranges2,V_total2)\n",
    "    real_pH = np.around((pH_Range.max() - pH_Range.min())*X_pH+pH_Range.min(),1)\n",
    "    \n",
    "    reagent_dic = {}\n",
    "    \n",
    "    reagents1[reagents1<=0] = 10**(-10)\n",
    "    reagents2[reagents2<=0] = 10**(-10)    \n",
    "    \n",
    "    for i in range(len(X1)):\n",
    "        reagent_dic[\"exp{}\".format(i)]={}\n",
    "        reagent_dic[\"exp{}\".format(i)][\"surfactant\"]=reagents1[i][0]\n",
    "        reagent_dic[\"exp{}\".format(i)][\"reductant\"]=reagents1[i][1]\n",
    "        reagent_dic[\"exp{}\".format(i)][\"water_reagent\"]=reagents1[i][2]\n",
    "        \n",
    "        reagent_dic[\"exp{}\".format(i)][\"silver\"]=reagents2[i][0]\n",
    "        reagent_dic[\"exp{}\".format(i)][\"gold\"]=reagents2[i][1]\n",
    "        \n",
    "        reagent_dic[\"exp{}\".format(i)][\"seeds\"]=0.5 \n",
    "        reagent_dic[\"exp{}\".format(i)][\"pH\"]=real_pH[i][0]\n",
    "        \n",
    "#     #add a reference experimental conditions to make sure Nanobot is working fine\n",
    "    reagent_dic[\"exp{}\".format(23)]={}\n",
    "    reagent_dic[\"exp{}\".format(23)][\"surfactant\"]=0.26\n",
    "    reagent_dic[\"exp{}\".format(23)][\"reductant\"]=0.20\n",
    "    reagent_dic[\"exp{}\".format(23)][\"water_reagent\"]=6.54\n",
    "\n",
    "    reagent_dic[\"exp{}\".format(23)][\"silver\"]=1.28\n",
    "    reagent_dic[\"exp{}\".format(23)][\"gold\"]=2.02\n",
    "\n",
    "    reagent_dic[\"exp{}\".format(23)][\"seeds\"]=0.5 \n",
    "    reagent_dic[\"exp{}\".format(23)][\"pH\"]=6.2\n",
    "\n",
    "    with open(base_directory+'data%d.json'%generation_num, 'w') as outfile:\n",
    "        json.dump(reagent_dic, outfile)\n",
    "    \n",
    "    # change the config file to the experiments to be conducted\n",
    "    config = json.load(open('./configs/experimental_information.json'))\n",
    "    config['title'] = f'MAP_elite_generation_{generation_num}'\n",
    "    with open('./configs/experimental_information.json', 'w') as f:\n",
    "        json.dump(config, f)\n",
    "    for i in range(len(reagent_dic)):\n",
    "        pathlib.Path('../data/custom/'+config['title']+f\"/00%02d/\"%(i)).mkdir(parents=True, exist_ok=True)\n",
    "        with open('../data/custom/'+config['title']+f\"/00%02d/\"%(i)+'params.json', 'w') as f:\n",
    "            json.dump(reagent_dic[\"exp{}\".format(i)], f,indent=4)\n",
    "            \n",
    "    with open('../data/custom/'+config['title']+'/flag1.txt', 'w') as f:\n",
    "        json.dump(1, f,indent=4)\n",
    "    # wait for the experiments to finish before continue the algorithim\n",
    "    while True:\n",
    "        if pathlib.Path(base_directory+\"MAP_elite_generation_%d\"%generation_num+'/flag3.txt').is_file():\n",
    "            break\n",
    "        time.sleep(2)\n",
    "    return reagents1,reagents2,X1,X2,X_pH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def objective_Nanobot(X1,X2,X_pH,generation_num):\n",
    "    \"\"\"\n",
    "    Read in the processed data except the last sample (because it's a reference sample)\n",
    "    Args:\n",
    "        X: the original X\n",
    "        generation_num: generation number\n",
    "    Returns:\n",
    "        X_new: the duplicated X (corresponding to peak system)\n",
    "        performance: the corresponding performance\n",
    "        index_set: the index\n",
    "        roughenss_set: the roughness of the sample UV-Vis\n",
    "    \"\"\"\n",
    "    data=np.load(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/data_total.npy\",allow_pickle=True)\n",
    "    data_pHs=np.load(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pHs.npy\",allow_pickle=True)\n",
    "    \n",
    "    performance = []\n",
    "    X1_new = []\n",
    "    X2_new = []\n",
    "    X_pH_new = []\n",
    "    index_set = []\n",
    "    roughness_set = []\n",
    "    prominence_set=[]\n",
    "    if len(X1) != 23:\n",
    "        print(\"Possible wrong X size!\")\n",
    "    for i in range(len(X1)):\n",
    "        data_temp = data[i]\n",
    "        if len(data_temp) == 0:\n",
    "            print(\"Sample %d has no data\" %i)\n",
    "            pass\n",
    "        else:\n",
    "            if data_temp[0] == 1:\n",
    "                pass\n",
    "            else:\n",
    "                pH_temp = (data_pHs[i] - pH_Range[0][0])/(pH_Range[0][1]-pH_Range[0][0])\n",
    "                if pH_temp>1:\n",
    "                    print(f\"actual pH is {pH_temp}\")\n",
    "                    pH_temp = 1\n",
    "                if pH_temp<0:\n",
    "                    print(f\"actual pH is {pH_temp}\")\n",
    "                    pH_temp = 0\n",
    "                X_pH_new.append(pH_temp)\n",
    "                X_pH_new.append(pH_temp)\n",
    "                X1_new.append(X1[i])\n",
    "                X1_new.append(X1[i])\n",
    "                X2_new.append(X2[i])\n",
    "                X2_new.append(X2[i])\n",
    "                performance.append(-0.002*(data_temp[3][0] + data_temp[3][1])+abs(data_temp[1][0] - data_temp[1][1]))\n",
    "                performance.append(-0.002*(data_temp[3][0] + data_temp[3][1])-abs(data_temp[1][0] - data_temp[1][1]))\n",
    "                index_set.append(100+100*data_temp[5][0]+data_temp[5][1])\n",
    "                index_set.append(10000+10000*data_temp[5][0]+data_temp[5][1])\n",
    "                roughness_set.append(data_temp[6])\n",
    "                roughness_set.append(data_temp[6])\n",
    "                prominence_set.append(data_temp[7])\n",
    "                prominence_set.append(data_temp[7])\n",
    "\n",
    "    return np.array(X1_new),np.array(X2_new),np.array(X_pH_new),np.array(performance).reshape(-1,1),np.array(index_set),np.array(roughness_set),np.array(prominence_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_num=4 # degree of freedoms in this experiment\n",
    "initial_num=23 # the initial random sampling number and here we apply 23 random experiments + 1 reference experiemnts\n",
    "batch_size=20 # the number of mutation+crossover in that generations, \n",
    "            # and we apply 20 normal experiments+ 3 random + 1 reference\n",
    "    \n",
    "mutation_rate=0.4 # the probability that a mutation can happen after cross-over\n",
    "sigma= 0.08 # the sigma of gassuain distribution in the mutation process\n",
    "\n",
    "generation_num=0\n",
    "\n",
    "#first, a random sampling is utilized to generate random samples\n",
    "X1 = obtain_constrained_random_samples(feature_num=2,initial_num=initial_num)\n",
    "X2 = obtain_constrained_random_samples(feature_num=2,initial_num=initial_num)\n",
    "\n",
    "Ranges1 = [[0,7], #CTAB\n",
    "           [0,7]] # Reductant\n",
    "\n",
    "Ranges2 = [[0,5],# Ag\n",
    "           [0,5]] #Au\n",
    "\n",
    "pH_Range = np.array([[4,8]]) # range of pH\n",
    "X_pH = obtain_constrained_random_samples(feature_num = 1,initial_num=initial_num)\n",
    "\n",
    "# print(np.concatenate((X1,X2,X_pH),axis=1))\n",
    "\n",
    "# then, a json_file is generated according to X and Ranges, constraning the overall volume and given the reference condition\n",
    "reagents1,reagents2,X1,X2,X_pH=generate_json_file_for_Nanobot(X1,\n",
    "                                                             X2,\n",
    "                                                             X_pH,\n",
    "                                                             Ranges1,\n",
    "                                                             Ranges2,\n",
    "                                                             pH_Range,\n",
    "                                                             V_total1 = 7,\n",
    "                                                             V_total2 = 5,\n",
    "                                                             generation_num=generation_num,\n",
    "                                                             random_sampling_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in the results from spectrum processor\n",
    "X1,X2,X_pH,performance,index,roughness,prominence_set=objective_Nanobot(X1,X2,X_pH,generation_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#filter bad data\n",
    "good_data_index=(roughness.flatten()<0.005) & (prominence_set>0.2)\n",
    "X1=X1[good_data_index]\n",
    "X2=X2[good_data_index]\n",
    "X_pH = X_pH[good_data_index]\n",
    "performance=performance[good_data_index]\n",
    "index=np.around(index[good_data_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create the initial pool\n",
    "pool_absorption=[]\n",
    "pool_absorption_pH = []\n",
    "#noting both performance are recorded and attached to the pool\n",
    "for attribute_index in np.unique(index):\n",
    "    performance_temp=performance[index==attribute_index]\n",
    "    X1_temp=X1[index==attribute_index]\n",
    "    X2_temp=X2[index==attribute_index]\n",
    "    X_pH_temp = X_pH[index==attribute_index]\n",
    "    \n",
    "    sample_1_index=np.argmax(performance_temp[:,0])\n",
    "    sample_1=np.concatenate((X1_temp[sample_1_index],X2_temp[sample_1_index],\n",
    "                             performance_temp[sample_1_index],\n",
    "                             [attribute_index]))\n",
    "    pool_absorption.append(sample_1)\n",
    "    pool_absorption_pH.append(X_pH_temp[sample_1_index])\n",
    "    \n",
    "pool_absorption=np.array(pool_absorption)\n",
    "pool_absorption_pH = np.array(pool_absorption_pH)\n",
    "\n",
    "np.savez(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption%d\"%generation_num,pool_absorption)\n",
    "np.savez(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption_pH%d\"%generation_num,pool_absorption_pH)\n",
    "\n",
    "generation_num=generation_num+1\n",
    "\n",
    "# print(len(pool_absorption))\n",
    "# print(len(pool_absorption_pH))\n",
    "# print(np.concatenate((pool_absorption,pool_absorption_pH.reshape(-1,1)),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the main part to run the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for loop in range(9):\n",
    "    #generate offspring according to the current pool\n",
    "    offspring,offspring_pH=generate_offspring(feature_num,pool_absorption,pool_absorption_pH,mutation_rate,sigma,batch_size)\n",
    "    print(np.concatenate((offspring,offspring_pH),axis=1))\n",
    "    reagents1,reagent2,X1,X2,X_pH=generate_json_file_for_Nanobot(offspring[:,0:2],\n",
    "                                                                   offspring[:,2:4],\n",
    "                                                                   offspring_pH,\n",
    "                                                                   Ranges1,\n",
    "                                                                   Ranges2,\n",
    "                                                                   pH_Range,\n",
    "                                                                   V_total1 = 7,\n",
    "                                                                   V_total2 = 5,\n",
    "                                                                   generation_num=generation_num)\n",
    "    offspring=np.hstack((X1,X2))\n",
    "    offspring_pH = X_pH\n",
    "    \n",
    "    # @RunNanobot\n",
    "    # Run nanobot and get the data\n",
    "#     input(\"Press Enter to continue after running the platform and analyzing the data ...\")\n",
    "    \n",
    "    #read in the current offspring results\n",
    "    X1,X2,offspring_pH,offspring_performance,offspring_index,roughness,prominence_set=objective_Nanobot(offspring[:,0:2],offspring[:,2:4],offspring_pH,generation_num)\n",
    "    offspring = np.hstack((X1,X2))\n",
    "#     print(offspring_pH)\n",
    "    #filter bad data\n",
    "    good_data_index = (roughness.flatten()<0.005) & (prominence_set>0.2)\n",
    "    offspring=offspring[good_data_index]\n",
    "    offspring_pH = offspring_pH[good_data_index]\n",
    "    offspring_performance=offspring_performance[good_data_index]\n",
    "    offspring_index=np.around(offspring_index[good_data_index])\n",
    "\n",
    "    #update the pool\n",
    "    pool_absorption,pool_absorption_pH=update_pool(offspring,offspring_pH.reshape(-1,1),offspring_performance,offspring_index,pool_absorption,pool_absorption_pH.reshape(-1,1))\n",
    "#     print(len(pool_absorption))\n",
    "#     print(len(pool_absorption_pH))\n",
    "#     print(np.concatenate((pool_absorption,pool_absorption_pH.reshape(-1,1)),axis=1))\n",
    "    np.savez(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption%d\"%generation_num,pool_absorption)\n",
    "    np.savez(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption_pH%d\"%generation_num,pool_absorption_pH)\n",
    "\n",
    "    generation_num=generation_num+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
