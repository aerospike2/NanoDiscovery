{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import find_peaks, peak_widths,peak_prominences\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(wavelengths,intensities,fc=15):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Use a low pass filter to deal with the read_in data.\n",
    "    Args:\n",
    "        wavelengths: the input wavelength.\n",
    "        intensities: the corresponding intensities of UV-Vis.\n",
    "        fc: frequency of low pass filter.\n",
    "    Returns:\n",
    "        series: the intensities passing through the low-pass filter.\n",
    "    \"\"\"\n",
    "    fs = wavelengths.shape[0]  # Sampling frequency\n",
    "    w = fc / (fs / 2) # Normalize the frequency\n",
    "    b, a = signal.butter(5, w, 'low')\n",
    "    series = signal.filtfilt(b, a, intensities)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_prominence(x,a=1,b=70,c=0.4,d=100,e=1,f=0.1,threshold=0.05):\n",
    "    \"\"\"\n",
    "    To do: \n",
    "        Definte a function which is more sensitive when x is small.\n",
    "    Args:\n",
    "        x: the peak prominence to be processed by this function.\n",
    "        a,b,c,d,e,f: constant the tune the shape of this function.\n",
    "        threshold: the threshold from where this function begin to behave like a linear function.\n",
    "    Returns:\n",
    "        The processed peak prominence after this function, which will be further used to calculate the scores.\n",
    "    \"\"\"\n",
    "    if x<threshold:\n",
    "        return (np.tanh((x-threshold)*d)+e)*f\n",
    "    else:\n",
    "        return (a*x+c*(1/(1+np.exp(-b*x))-0.5))/(a+c*(1/(1+np.exp(-b))-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_binary(x,b=100,threshold=0.05):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Use a tanh function to binarize peaks accoridng to its promiencen.\n",
    "    Args:\n",
    "        x: the peak prominence to be processed by this function.\n",
    "        b: a variable to tune the shape of this function.\n",
    "        threshold: the threshold after which the function behave like a linear function.\n",
    "    Returns:\n",
    "        the processed peak prominence.\n",
    "    \"\"\"\n",
    "    return (np.tanh((x-threshold)*b)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizedata(series_original):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Definte a function which normalize the input data into range (0,1).\n",
    "        \n",
    "    \"\"\"\n",
    "    return (series_original-np.min(series_original))/(np.max(series_original)-np.min(series_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_smoothness(x):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Calculate the smootheness of the spectrum. \n",
    "        The smoothness is defined byy the absolute difference between the original spectrum and the spectrum after low-pass filter.\n",
    "    Args:\n",
    "        x: the UV-Vis spectrum\n",
    "    Returns:\n",
    "        The quantity measuring the smootheness of this spectrum.\n",
    "    \"\"\"\n",
    "    return np.std(np.diff(x))/abs(np.mean(np.diff(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_UV_Vis(base_sample,index,lower=400,upper=950,fc=15,color=\"red\",plot_flag=True,normalize=False):\n",
    "    #Read in json file\n",
    "    with open(base_sample+f\"00%02d/uv.json\"%(index)) as json_data:\n",
    "        d = json.load(json_data)\n",
    "        #read wavelength and intensities\n",
    "        wavelengths = np.array(d['wavelength'])\n",
    "        series_original = np.array(d['absorbances'])\n",
    "    #trim data\n",
    "    series_original = series_original[(wavelengths>lower) & (wavelengths < upper)]\n",
    "    wavelengths = wavelengths[(wavelengths>lower) & (wavelengths < upper)]\n",
    "    #trim data in the range of lower to upper\n",
    "    series_original=normalizedata(series_original[(wavelengths>lower) & (wavelengths < upper)])\n",
    "    series=low_pass_filter(wavelengths,series_original,fc=fc)\n",
    "    roughness=abs(series-series_original).mean()\n",
    "    \n",
    "    series=normalizedata(series)\n",
    "    \n",
    "    if plot_flag and normalize==True:\n",
    "        plt.plot(wavelengths,series,c=\"black\")\n",
    "        plt.plot(wavelengths,series_original,c=color)\n",
    "    \n",
    "    UV_inter = interp1d(wavelengths, series, kind='cubic',fill_value='extrapolate' )\n",
    "    return UV_inter,roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1D(region,boundary,roughness,series,peaks,prominences,wavelengths):    \n",
    "    #plot part\n",
    "    plt.figure()\n",
    "        \n",
    "    plt.plot(wavelengths,series)\n",
    "    plt.plot(wavelengths[peaks], series[peaks], \"x\")\n",
    "    plt.vlines(boundary, ymin=0, ymax=1,color=\"r\",linestyles =\"dashed\")\n",
    "    for region_temp in region:\n",
    "        plt.vlines(region, ymin=0, ymax=1,color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_scores(base_sample,index,boundary1,boundary2,near_width=50,lower=400,upper=950,num=101,False_width=10000,plot_flag=True):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Calculate the defined UV-Vis scores of a sample.\n",
    "    Args:\n",
    "        base_sample: the directory of the sample\n",
    "        index: the index of the sample\n",
    "        boundary1: the boundaries to diecretize the UV-Vis region for one peak system\n",
    "        boundary2: the boundaries to discretize the UV-Vis spectrum for two peak system\n",
    "        near_width: the width to define the nearby region\n",
    "        lower: the lower wavelength boundary of UV-Vis\n",
    "        upper: the upper wavelength boundary of UV-Vis\n",
    "        num: the sampling number in wavelength [lower,upper]\n",
    "        False_width: the width this function returns when there's no peak in the system\n",
    "    Returns:\n",
    "        \n",
    "   \"\"\"\n",
    "    UV_sample,roughness=read_in_UV_Vis(base_sample,index,plot_flag=plot_flag)\n",
    "\n",
    "    #define the wavelength and got the UV-Vis spectrum\n",
    "    wavelengths=np.linspace(lower,upper,num)\n",
    "\n",
    "    series=UV_sample(wavelengths)\n",
    "\n",
    "    #find peaks in the data\n",
    "    peaks, _ = find_peaks(series,prominence=0.02)\n",
    "    if len(peaks) == 0:\n",
    "        print(\"None peaks are found!\")\n",
    "        plt.close()\n",
    "        return []\n",
    "    #find prominence of individual peaks\n",
    "    prominences = peak_prominences(series, peaks)[0]\n",
    "    results_half = peak_widths(series, peaks, rel_height=0.5)\n",
    "    results_full = peak_widths(series, peaks, rel_height=1)\n",
    "    \n",
    "    # if the peak number are larger than 2\n",
    "    if len(prominences) >=2 :\n",
    "        #obtain the largest two peaks\n",
    "        peak_index = prominences.argsort()[-2:][::-1]\n",
    "        peak_position1 = wavelengths[peaks[peak_index[0]]]\n",
    "        peak_position2 = wavelengths[peaks[peak_index[1]]]\n",
    "        #judge the grid this sample belongs to \n",
    "        peak_class1 = bisect.bisect_left(boundary2, peak_position1)\n",
    "        peak_class2 = bisect.bisect_left(boundary2, peak_position2)\n",
    "        sample_class_index = [peak_class1,peak_class2]\n",
    "        \n",
    "        # get the nearby region of the first peak\n",
    "        region1 = [[peak_position1-near_width,peak_position1+near_width]]\n",
    "        #select the domain for the highest peak\n",
    "        region2 = [[peak_position2-near_width,peak_position2+near_width]]\n",
    "        \n",
    "        # get the peak width\n",
    "        width1 = results_half[0][peak_index[0]].item()*(wavelengths[1]-wavelengths[0])\n",
    "        width2 = results_half[0][peak_index[1]].item()*(wavelengths[1]-wavelengths[0])\n",
    "        \n",
    "        # calculate the peak absorption respectively\n",
    "        score1 = series[(wavelengths > region1[0][0]) & (wavelengths < region1[0][1])].mean()\n",
    "\n",
    "        score2 = series[(wavelengths > region2[0][0]) & (wavelengths < region2[0][1])].mean()\n",
    "\n",
    "        score4 = series[(wavelengths > boundary2[peak_class1-1]) & (wavelengths < boundary2[peak_class1])].mean()\n",
    "        \n",
    "        score5 = series[(wavelengths > boundary2[peak_class2-1]) & (wavelengths < boundary2[peak_class2])].mean()\n",
    "        \n",
    "        score_extra = series[(wavelengths > 550) & (wavelengths < 600)].mean()\n",
    "        \n",
    "    #deal with single peak system\n",
    "    #calculated absorption band is recorded as score3\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    if len(prominences) >=2 and sample_class_index[0]>sample_class_index[1]:\n",
    "        if plot_flag:\n",
    "            #plot the absorption domains\n",
    "            plot_1D(region1+region2,boundary2,roughness,series,peaks,prominences,wavelengths)\n",
    "            contour_heights = series[peaks] - prominences\n",
    "            if len(results_half[0])>0:\n",
    "                plt.scatter(wavelengths[_['left_bases']],series[_['left_bases']],c='black')\n",
    "                plt.scatter(wavelengths[_['right_bases']],series[_['right_bases']],c='black')\n",
    "                plt.vlines(x=wavelengths[peaks], ymin=contour_heights, ymax=series[peaks])\n",
    "                plt.hlines(*(results_half[1],wavelengths[np.around(results_half[2]).astype(\"int\")],wavelengths[np.around(results_half[3]).astype(\"int\")]), color=\"C2\")\n",
    "                plt.hlines(*(results_full[1],wavelengths[np.around(results_full[2]).astype(\"int\")],wavelengths[np.around(results_full[3]).astype(\"int\")]), color=\"C3\")\n",
    "            plt.show()\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #return the results\n",
    "    if len(prominences) >=2 and sample_class_index[0]>sample_class_index[1]:\n",
    "        return np.array([2,\n",
    "                         score1,\n",
    "                         score2,\n",
    "                         score4,\n",
    "                         [score5,score_extra],\n",
    "                         width1,\n",
    "                         width2,\n",
    "                         sample_class_index,\n",
    "                         roughness,\n",
    "                         prominences.max()])\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all the data from exploration experiment and save them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for generation_num in range(10):\n",
    "    work_directory = f\"./\"\n",
    "    base_sample=f\"../0/MAP_elite_generation_{generation_num}/\"\n",
    "    data_output_total=[]\n",
    "    \n",
    "    synthesis_all = []\n",
    "    for j in range(23):\n",
    "        with open(base_sample+\"/%04d\"%j+\"/params.json\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "            synthesis_temp = [data[\"gold\"],data[\"surfactant\"],data[\"silver\"],data[\"reductant\"],data[\"water\"]]\n",
    "            synthesis_all.append(synthesis_temp)        \n",
    "    synthesis_all = np.array(synthesis_all)\n",
    "    np.save(work_directory+\"/Initial_set/\"+f\"synthesis_conditions{generation_num}\",synthesis_all)\n",
    "    \n",
    "    for i in range(23):\n",
    "        print(i)\n",
    "        data_output=obtain_scores(base_sample,\n",
    "                                  i,\n",
    "                                  boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                                  boundary2=np.linspace(400,950,12),\n",
    "                                  near_width=50,\n",
    "                                  lower=400,\n",
    "                                  upper=950,\n",
    "                                  num=1101,\n",
    "                                  False_width=10000,plot_flag = False)\n",
    "        plt.close()\n",
    "        if len(data_output)>0:\n",
    "            # double peak system\n",
    "            if data_output[0] ==2:\n",
    "                # if it's good data\n",
    "                if data_output[-1] > 0.2 and data_output[-2] < 0.005:\n",
    "                    data_output=obtain_scores(base_sample,\n",
    "                          i,\n",
    "                          boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                          boundary2=np.linspace(400,950,12),\n",
    "                          near_width=50,\n",
    "                          lower=400,\n",
    "                          upper=950,\n",
    "                          num=1101,\n",
    "                          False_width=10000,plot_flag = True)\n",
    "        data_output_total.append(data_output)\n",
    "    data_output_total=np.array(data_output_total)\n",
    "    np.save(work_directory+\"/Initial_set/\"+f\"data_total{generation_num}\",data_output_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for generation_num in range(1,5):\n",
    "    input(\"Press Enter to continue after running the platform and acquiring the data ...\")\n",
    "    base_sample=\"./MAP_elite_generation_%d/\"%generation_num\n",
    "    data_output_total=[]\n",
    "    for i in range(24):\n",
    "        print(i)\n",
    "        data_output=obtain_scores(base_sample,\n",
    "                                  i,\n",
    "                                  boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                                  boundary2=np.linspace(400,950,12),\n",
    "                                  near_width=50,\n",
    "                                  lower=400,\n",
    "                                  upper=950,\n",
    "                                  num=1101,\n",
    "                                  False_width=10000)\n",
    "        print(data_output)\n",
    "        if len (data_output)>0:\n",
    "            print(-0.01*data_output[5] - data_output[2])\n",
    "\n",
    "        data_output_total.append(data_output)\n",
    "    data_output_total=np.array(data_output_total)\n",
    "    np.save(base_sample+\"data_total\",data_output_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View which conditions are in the pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool=[]\n",
    "total_generations = 5\n",
    "for generation_num in range(total_generations):\n",
    "    base_directory=\"./\"\n",
    "    path=base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption%d.npz\"%generation_num\n",
    "    pool_temp = np.load(path,allow_pickle=True)[\"arr_0\"]\n",
    "    pool.append(pool_temp[pool_temp[:,-1].argsort()])\n",
    "plt.xlabel(\"generation\")\n",
    "plt.ylabel(\"grid number\")\n",
    "plt.scatter(np.arange(len(pool)),np.array([len(pool_temp) for pool_temp in pool]))\n",
    "plt.plot(np.array([len(pool_temp) for pool_temp in pool]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_total = []\n",
    "for grid_index in range(len(pool[-1][:,-1])):\n",
    "    fitness_temp = []\n",
    "    for generation_num in range(total_generations):\n",
    "        fitness_temp.append((pool[generation_num][pool[generation_num][:,-1] == pool[-1][:,-1][grid_index]])[:,-2])\n",
    "    for index_temp in range(len(fitness_temp)):\n",
    "        if len(fitness_temp[index_temp]) == 0:\n",
    "            fitness_temp[index_temp] = None\n",
    "    fitness_total.append(fitness_temp)\n",
    "best_grids = np.unique(pool[-1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for grid_index in range(len(pool[-1][:,-1])):\n",
    "    print(fitness_total[grid_index])\n",
    "    if fitness_total[grid_index][-2] != None:\n",
    "        print(fitness_total[grid_index][-1] - fitness_total[grid_index][-2])\n",
    "    plt.scatter(np.arange(len(fitness_total[grid_index])),fitness_total[grid_index])\n",
    "    plt.plot(np.arange(len(fitness_total[grid_index])),fitness_total[grid_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out the synthetic condition and its corresponding scores.\n",
    "# Store them for further optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ranges=[[0,11.5], #Au\n",
    "        [0,11.5], #CTAB\n",
    "        [0,11.5], #Ag\n",
    "        [0,11.5]] #Reductant\n",
    "def create_reagent_volume(X,Ranges,V_total=11.5):\n",
    "    X_new=np.zeros((X.shape))\n",
    "    for i in range(len(Ranges)):\n",
    "        X_new[:,i]=X[:,i]*(Ranges[i][1]-Ranges[i][0])+Ranges[i][0]\n",
    "    X_new=np.around(X_new,2)\n",
    "    X_final=np.hstack((X_new,V_total-X_new.sum(axis=1).reshape(-1,1)))\n",
    "    return np.around(X_final,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_condition = create_reagent_volume(best_grids[:,0:4],Ranges,11.5)\n",
    "synthetic_condition[synthetic_condition<=0] = 10**(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_total = []\n",
    "set_index = []\n",
    "data_total_pool = []\n",
    "for synthetic_condition_index in range(len(synthetic_condition)):\n",
    "    synthetic_condition_temp = synthetic_condition[synthetic_condition_index]\n",
    "    print(synthetic_condition_index)\n",
    "    \n",
    "    for generation_num in range(10):\n",
    "        base_directory=\"../0/\"+\"MAP_elite_generation_%d/\"%generation_num\n",
    "        for j in range(23):\n",
    "            with open(base_directory+\"/%04d\"%j+\"/params.json\") as json_file:\n",
    "                data = json.load(json_file)\n",
    "                synthesis_temp = [data[\"gold\"],data[\"surfactant\"],data[\"silver\"],data[\"reductant\"],data[\"water\"]]\n",
    "                \n",
    "            if sum(np.array(synthesis_temp) == synthetic_condition_temp) == len(synthetic_condition_temp):\n",
    "                data_output=obtain_scores(base_directory,\n",
    "                                          j,\n",
    "                                          boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                                          boundary2=np.linspace(400,950,12),\n",
    "                                          near_width=50,\n",
    "                                          lower=400,\n",
    "                                          upper=950,\n",
    "                                          num=1101,\n",
    "                                          False_width=10000,\n",
    "                                          plot_flag=False\n",
    "                                         ) \n",
    "                plt.close()\n",
    "                \n",
    "                if data_output[0]==2 and -0.002*data_output[5] - data_output[2] == best_grids[synthetic_condition_index][-2]:\n",
    "                    \n",
    "                    print(\"this sample is found during first stage\")\n",
    "                    print(generation_num,j) \n",
    "                    print(synthetic_condition_temp)\n",
    "                    print(-0.002*(data_output[5]+data_output[6]) - data_output[4][1]- data_output[2])\n",
    "                    print(data_output)\n",
    "                    set_index.append(0)\n",
    "                    data_total_pool.append(\n",
    "                        obtain_scores(base_directory,\n",
    "                                              j,\n",
    "                                              boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                                              boundary2=np.linspace(400,950,12),\n",
    "                                              near_width=50,\n",
    "                                              lower=400,\n",
    "                                              upper=950,\n",
    "                                              num=1101,\n",
    "                                              False_width=10000,\n",
    "                                              plot_flag=True\n",
    "                                             ))\n",
    "                    plt.close()\n",
    "                    index_total.append([generation_num,j,best_grids[synthetic_condition_index][-1],1])\n",
    "                    \n",
    "                    \n",
    "    for generation_num in range(1,total_generations):\n",
    "        base_directory=\"./\"+\"MAP_elite_generation_%d/\"%generation_num\n",
    "        for j in range(23):\n",
    "            with open(base_directory+\"/%04d\"%j+\"/params.json\") as json_file:\n",
    "                data = json.load(json_file)\n",
    "                synthesis_temp = [data[\"gold\"],data[\"surfactant\"],data[\"silver\"],data[\"reductant\"],data[\"water\"]]\n",
    "                \n",
    "            if sum(np.array(synthesis_temp) == synthetic_condition_temp) == len(synthetic_condition_temp):\n",
    "                data_output=obtain_scores(base_directory,\n",
    "                                          j,\n",
    "                                          boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                                          boundary2=np.linspace(400,950,12),\n",
    "                                          near_width=50,\n",
    "                                          lower=400,\n",
    "                                          upper=950,\n",
    "                                          num=1101,\n",
    "                                          False_width=10000,\n",
    "                                          plot_flag=False\n",
    "                                         ) \n",
    "                plt.close()\n",
    "                \n",
    "                if data_output[0]==2 and -0.002*data_output[5] - data_output[2] == best_grids[synthetic_condition_index][-2]:\n",
    "                    print(\"this sample is found during secondary stage\")\n",
    "                    print(generation_num,j) \n",
    "                    print(synthetic_condition_temp)\n",
    "                    print(-0.002*(data_output[5]+data_output[6]) - data_output[4][1] - data_output[2])\n",
    "                    print(print(data_output))\n",
    "                    set_index.append(1)\n",
    "                    data_total_pool.append(\n",
    "                        obtain_scores(base_directory,\n",
    "                                              j,\n",
    "                                              boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                                              boundary2=np.linspace(400,950,12),\n",
    "                                              near_width=50,\n",
    "                                              lower=400,\n",
    "                                              upper=950,\n",
    "                                              num=1101,\n",
    "                                              False_width=10000,\n",
    "                                              plot_flag=True\n",
    "                                             ))\n",
    "                    plt.close()\n",
    "                    index_total.append([generation_num,j,best_grids[synthetic_condition_index][-1],2])\n",
    "    \n",
    "    print(\"==============================\")\n",
    "index_total = np.array(index_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./\"+\"data_total_pool\",data_total_pool)\n",
    "np.save(\"./\"+\"data_total_pool_X\",synthetic_condition/11.5)\n",
    "np.save(\"./\"+\"index_total\",index_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
