{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import find_peaks, peak_widths,peak_prominences\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(wavelengths,intensities,fc=15):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Use a low pass filter to deal with the read_in data.\n",
    "    Args:\n",
    "        wavelengths: the input wavelength.\n",
    "        intensities: the corresponding intensities of UV-Vis.\n",
    "        fc: frequency of low pass filter.\n",
    "    Returns:\n",
    "        series: the intensities passing through the low-pass filter.\n",
    "    \"\"\"\n",
    "    fs = wavelengths.shape[0]  # Sampling frequency\n",
    "    w = fc / (fs / 2) # Normalize the frequency\n",
    "    b, a = signal.butter(5, w, 'low')\n",
    "    series = signal.filtfilt(b, a, intensities)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_prominence(x,a=1,b=70,c=0.4,d=100,e=1,f=0.1,threshold=0.05):\n",
    "    \"\"\"\n",
    "    To do: \n",
    "        Definte a function which is more sensitive when x is small.\n",
    "    Args:\n",
    "        x: the peak prominence to be processed by this function.\n",
    "        a,b,c,d,e,f: constant the tune the shape of this function.\n",
    "        threshold: the threshold from where this function begin to behave like a linear function.\n",
    "    Returns:\n",
    "        The processed peak prominence after this function, which will be further used to calculate the scores.\n",
    "    \"\"\"\n",
    "    if x<threshold:\n",
    "        return (np.tanh((x-threshold)*d)+e)*f\n",
    "    else:\n",
    "        return (a*x+c*(1/(1+np.exp(-b*x))-0.5))/(a+c*(1/(1+np.exp(-b))-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_binary(x,b=100,threshold=0.05):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Use a tanh function to binarize peaks accoridng to its promiencen.\n",
    "    Args:\n",
    "        x: the peak prominence to be processed by this function.\n",
    "        b: a variable to tune the shape of this function.\n",
    "        threshold: the threshold after which the function behave like a linear function.\n",
    "    Returns:\n",
    "        the processed peak prominence.\n",
    "    \"\"\"\n",
    "    return (np.tanh((x-threshold)*b)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizedata(series_original):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Definte a function which normalize the input data into range (0,1).\n",
    "        \n",
    "    \"\"\"\n",
    "    return (series_original-np.min(series_original))/(np.max(series_original)-np.min(series_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_smoothness(x):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Calculate the smootheness of the spectrum. \n",
    "        The smoothness is defined byy the absolute difference between the original spectrum and the spectrum after low-pass filter.\n",
    "    Args:\n",
    "        x: the UV-Vis spectrum\n",
    "    Returns:\n",
    "        The quantity measuring the smootheness of this spectrum.\n",
    "    \"\"\"\n",
    "    return np.std(np.diff(x))/abs(np.mean(np.diff(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_UV_Vis(base_sample,index,lower=400,upper=950,fc=15,color=\"red\",plot_flag=True,normalize=False):\n",
    "    #Read in json file\n",
    "    with open(base_sample+f\"00%02d/uv.json\"%(index)) as json_data:\n",
    "        d = json.load(json_data)\n",
    "        #read wavelength and intensities\n",
    "        wavelengths = np.array(d['wavelength'])\n",
    "        series_original = np.array(d['absorbances'])\n",
    "    #trim data\n",
    "    series_original = series_original[(wavelengths>lower) & (wavelengths < upper)]\n",
    "    wavelengths = wavelengths[(wavelengths>lower) & (wavelengths < upper)]\n",
    "    #trim data in the range of lower to upper\n",
    "    series_original=normalizedata(series_original[(wavelengths>lower) & (wavelengths < upper)])\n",
    "    series=low_pass_filter(wavelengths,series_original,fc=fc)\n",
    "    roughness=abs(series-series_original).mean()\n",
    "    \n",
    "    series=normalizedata(series)\n",
    "    \n",
    "    if plot_flag and normalize==True:\n",
    "        plt.plot(wavelengths,series,c=\"black\")\n",
    "        plt.plot(wavelengths,series_original,c=color)\n",
    "    \n",
    "    UV_inter = interp1d(wavelengths, series, kind='cubic',fill_value='extrapolate' )\n",
    "    return UV_inter,roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1D(region,boundary,roughness,series,peaks,prominences,wavelengths):\n",
    "    #plot part\n",
    "    plt.figure()\n",
    "        \n",
    "    plt.plot(wavelengths,series,\"black\")\n",
    "    plt.plot(wavelengths[peaks], series[peaks], \"x\")\n",
    "    plt.vlines(boundary, ymin=0, ymax=1,color=\"r\",linestyles =\"dashed\")\n",
    "    for region_temp in region:\n",
    "        plt.vlines(region, ymin=0, ymax=1,color=\"b\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_scores(base_sample,index,boundary1,boundary2,near_width=50,lower=400,upper=950,num=101,False_width=10000,plot_flag=True):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Calculate the defined UV-Vis scores of a sample.\n",
    "    Args:\n",
    "        base_sample: the directory of the sample\n",
    "        index: the index of the sample\n",
    "        boundary1: the boundaries to diecretize the UV-Vis region for one peak system\n",
    "        boundary2: the boundaries to discretize the UV-Vis spectrum for two peak system\n",
    "        near_width: the width to define the nearby region\n",
    "        lower: the lower wavelength boundary of UV-Vis\n",
    "        upper: the upper wavelength boundary of UV-Vis\n",
    "        num: the sampling number in wavelength [lower,upper]\n",
    "        False_width: the width this function returns when there's no peak in the system\n",
    "    Returns:\n",
    "        \n",
    "   \"\"\"\n",
    "    UV_sample,roughness=read_in_UV_Vis(base_sample,index,plot_flag=plot_flag)\n",
    "\n",
    "    #define the wavelength and got the UV-Vis spectrum\n",
    "    wavelengths=np.linspace(lower,upper,num)\n",
    "\n",
    "    series=UV_sample(wavelengths)\n",
    "\n",
    "    #find peaks in the data\n",
    "    peaks, _ = find_peaks(series,prominence=0.02)\n",
    "    if len(peaks) == 0:\n",
    "        print(\"None peaks are found!\")\n",
    "        plt.close()\n",
    "        return []\n",
    "    #find prominence of individual peaks\n",
    "    prominences = peak_prominences(series, peaks)[0]\n",
    "    \n",
    "    # if the peak number are larger than 2\n",
    "    if len(prominences) >=2 :\n",
    "        #obtain the largest two peaks\n",
    "        peak_index = prominences.argsort()[-2:][::-1]\n",
    "        peak_position1 = wavelengths[peaks[peak_index[0]]]\n",
    "        peak_position2 = wavelengths[peaks[peak_index[1]]]\n",
    "        #judge the grid this sample belongs to \n",
    "        peak_class1 = bisect.bisect_left(boundary2, peak_position1)\n",
    "        peak_class2 = bisect.bisect_left(boundary2, peak_position2)\n",
    "        sample_class_index = [peak_class1,peak_class2]\n",
    "        #obtian the original domain\n",
    "        region = [[peak_position1-near_width,peak_position1+near_width],\n",
    "                  [peak_position2-near_width,peak_position2+near_width]]\n",
    "        #if the domain overlaps, choose the overall domain\n",
    "        if ((peak_position1 < peak_position2) and (peak_position1+near_width > peak_position2-near_width)):\n",
    "            region = [[peak_position1-near_width,peak_position2+near_width]]\n",
    "        elif ((peak_position2 < peak_position1) and (peak_position2+near_width > peak_position1-near_width)):\n",
    "            region = [[peak_position2-near_width,peak_position1+near_width]]\n",
    "                \n",
    "        #select the domain for the highest peak\n",
    "        region2 = [[peak_position1-near_width,peak_position1+near_width]]\n",
    "        \n",
    "        #calculate the absorption band for two absorption bands and record as scrore1 \n",
    "        #calculate the absorption band for the absorption band defined by more prominent peak and record as score2\n",
    "        absorption_band=0\n",
    "        for i in range(len(region)):\n",
    "            region_temp = region[i]\n",
    "            absorption_band = absorption_band + series[(wavelengths > region_temp[0]) & (wavelengths < region_temp[1])].sum()\n",
    "        score1 = absorption_band\n",
    "        score2 = series[(wavelengths > region2[0][0]) & (wavelengths < region2[0][1])].sum()\n",
    "        score1 = score1/series.sum()\n",
    "        score2 = score2/series.sum()\n",
    "#         print(\"score1 is %f\"%score1)\n",
    "#         print(\"score2 is %f\"%score2)\n",
    "    #deal with single peak system\n",
    "    #calculated absorption band is recorded as score3\n",
    "    else:\n",
    "        sample_class_index = bisect.bisect_left(boundary1, wavelengths[peaks[0]])\n",
    "        region = [[wavelengths[peaks[0]]-near_width, wavelengths[peaks[0]]+near_width]]\n",
    "        score3 = series[(wavelengths > region[0][0]) & (wavelengths < region[0][1])].sum()\n",
    "        score3 = score3/series.sum()\n",
    "#         print(\"score3 is %f\"%score3)\n",
    "        \n",
    "#     print(region)\n",
    "#     print(roughness)\n",
    "    if len(prominences) >=2:\n",
    "        if plot_flag:\n",
    "            #plot the absorption domains\n",
    "            plot_1D(region,boundary2,roughness,series,peaks,prominences,wavelengths)\n",
    "            plt.close()\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(wavelengths,series,c=\"black\")\n",
    "            plt.fill_between(wavelengths,series, color='blue', \n",
    "                 alpha=0.5) \n",
    "            for region_temp in region:\n",
    "                plt.fill_between(wavelengths[(wavelengths>region_temp[0]) & (wavelengths<region_temp[1])],series[(wavelengths>region_temp[0]) & (wavelengths<region_temp[1])], color=\"blue\", \n",
    "                                 alpha=0.5) \n",
    "            plt.show()\n",
    "            plt.close()\n",
    "    else:\n",
    "        if plot_flag:\n",
    "            plot_1D(region,boundary1,roughness,series,peaks,prominences,wavelengths)\n",
    "            \n",
    "    #return the results\n",
    "    if len(prominences) >=2 :\n",
    "        return np.array([2,score1,score2,sample_class_index,roughness,prominences.max()])\n",
    "    else:\n",
    "        return np.array([1,score3,sample_class_index,roughness,prominences.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the data from experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for generation_num in range(10):\n",
    "    input(\"Press Enter to continue after running the platform and acquiring the data ...\")\n",
    "    base_sample=\"./MAP_elite_generation_%d/\"%generation_num\n",
    "    data_output_total=[]\n",
    "    for i in range(24):\n",
    "        print(i)\n",
    "        data_output=obtain_scores(base_sample,\n",
    "                                  i,\n",
    "                                  boundary1=np.concatenate((np.linspace(400,600,9),np.linspace(600,950,8)[1:])),\n",
    "                                  boundary2=np.linspace(400,950,12),\n",
    "                                  near_width=50,\n",
    "                                  lower=400,\n",
    "                                  upper=950,\n",
    "                                  num=1101,\n",
    "                                  False_width=10000)\n",
    "        print(data_output)\n",
    "        data_output_total.append(data_output)\n",
    "    data_output_total=np.array(data_output_total)\n",
    "    np.save(base_sample+\"data_total\",data_output_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View which conditions are in the pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool=[]\n",
    "total_generations = 10\n",
    "for generation_num in range(total_generations):\n",
    "    base_directory=\"./\"\n",
    "    path=base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption%d.npz\"%generation_num\n",
    "    pool_temp = np.load(path,allow_pickle=True)[\"arr_0\"]\n",
    "    pool.append(pool_temp[pool_temp[:,-1].argsort()])\n",
    "plt.xlabel(\"generation\")\n",
    "plt.ylabel(\"elite number\")\n",
    "plt.scatter(np.arange(len(pool)),np.array([len(pool_temp) for pool_temp in pool]),c = \"black\")\n",
    "plt.plot(np.array([len(pool_temp) for pool_temp in pool]),c = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_total = []\n",
    "for grid_index in range(len(pool[-1][:,-1])):\n",
    "    fitness_temp = []\n",
    "    for generation_num in range(total_generations):\n",
    "        fitness_temp.append((pool[generation_num][pool[generation_num][:,-1] == pool[-1][:,-1][grid_index]])[:,-2])\n",
    "    for index_temp in range(len(fitness_temp)):\n",
    "        if len(fitness_temp[index_temp]) == 0:\n",
    "            fitness_temp[index_temp] = None\n",
    "    fitness_total.append(fitness_temp)\n",
    "best_grids = np.unique(pool[-1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for grid_index in range(len(pool[-1][:,-1])):\n",
    "    print(fitness_total[grid_index])\n",
    "    if fitness_total[grid_index][-2] != None:\n",
    "        print(fitness_total[grid_index][-1] - fitness_total[grid_index][-2])\n",
    "    plt.scatter(np.arange(len(fitness_total[grid_index])),fitness_total[grid_index])\n",
    "    plt.plot(np.arange(len(fitness_total[grid_index])),fitness_total[grid_index])\n",
    "plt.xlabel(\"generation\")\n",
    "plt.ylabel(\"fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
