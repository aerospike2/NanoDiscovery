{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory=\"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_random_samples(feature_num,initial_num=10):\n",
    "    \"\"\"\n",
    "    To do: generate random uniformly distributed initial samples\n",
    "    Args:\n",
    "        feature_num: number of features\n",
    "        initial_num: number of initial samples\n",
    "    Returns:\n",
    "        X: randomly generated samples\n",
    "    \"\"\"\n",
    "    X_initial=np.random.uniform(size=(initial_num,feature_num-1))\n",
    "    X_temp=np.sort(np.hstack((np.hstack((np.zeros((X_initial.shape[0],1)),X_initial)),np.ones((X_initial.shape[0],1)))))\n",
    "    X=np.diff(X_temp,axis=-1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_constrained_random_samples(feature_num,constrain=1,initial_num=10):\n",
    "    \"\"\"\n",
    "    To do: generate random uniformly distributed initial samples with a linear constrain\n",
    "    Args:\n",
    "        feature_num: number of features\n",
    "        initial_num: number of initial samples\n",
    "    Returns:\n",
    "        X: randomly generated samples\n",
    "    \"\"\"\n",
    "    X = np.empty((0,feature_num))\n",
    "    while len(X) < initial_num:\n",
    "        X_temp = np.random.uniform(0,1,(1,feature_num))\n",
    "        if X_temp.sum() <= constrain:\n",
    "            X = np.append(X,X_temp,axis=0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_over(pool_absorption,feature_num):\n",
    "    \"\"\"\n",
    "    To do: cross-over based on the pool of absorption\n",
    "    Args:\n",
    "        pool_absorption: the pool of high absoprtion performance\n",
    "        feature_num: the number of sample features\n",
    "    Returns:\n",
    "        offspring: the offspring after crossover\n",
    "    \"\"\"\n",
    "    pool=np.array(pool_absorption)[:,0:feature_num]\n",
    "    index=np.random.choice(len(pool),size=2,replace=True)\n",
    "    offspring=np.zeros((1,feature_num))\n",
    "    for i in range(feature_num):\n",
    "        offspring[0,i]=pool[index[np.random.randint(2)]][i]\n",
    "    print(\"crossover\")\n",
    "    print(index)\n",
    "    print(offspring)\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(offspring,mutate_rate,sigma,constrain=1):\n",
    "    \"\"\"\n",
    "    To do: mutate the genotype of the offsprings\n",
    "    Args:\n",
    "        offspring: the offspring to be evaluated\n",
    "        mutate_rate: the probability of mutation\n",
    "    Returns:\n",
    "        mutated_offspring: the mutated offspring\n",
    "        mutation_flag: the flag indicating if mutation happened\n",
    "    \"\"\"\n",
    "    offspring=offspring.reshape(1,-1)\n",
    "    # keeping tracing the numerical error and get rid of possible numerical error\n",
    "    if offspring.sum() > constrain:\n",
    "        offspring = offspring/offspring.sum()\n",
    "        \n",
    "    solutions=[]\n",
    "    if np.random.random() < mutate_rate:\n",
    "        print(\"mutation_operation on\")\n",
    "        mutation_direction = np.random.normal(0,sigma,offspring.shape)\n",
    "        offspring_direct = offspring + mutation_direction\n",
    "        # after direct mutation, check if all the constrains are satisfied\n",
    "        # if not, calculate the minimum distance we can add with this mutation direction\n",
    "        if offspring_direct.sum()>constrain:\n",
    "            solutions.append((constrain-offspring.sum())/mutation_direction.sum())\n",
    "        index = np.where(offspring_direct<0)\n",
    "        for x in range(len(index[0])):\n",
    "            solutions.append(0-offspring[index[0][x],index[1][x]]/mutation_direction[index[0][x],index[1][x]])\n",
    "        solutions = np.array(solutions)\n",
    "        # sometimes because of numerical error, the minimum quantity is not 0 but smaller than zero\n",
    "        # the absolute value is small enough but we still want to see it\n",
    "        if (np.array(solutions)<0).sum()>0:\n",
    "            print(\"warning:mutation_direction changed in mutation!\")\n",
    "            print(solutions)\n",
    "        # get rid of the numerical error mentioned above by setting it to 0\n",
    "        solutions[solutions<1e-10] = 0\n",
    "        \n",
    "        if len(solutions)>0: # return the mutation result under absoprtion boundary condition\n",
    "            return offspring+np.min(solutions)*mutation_direction,True\n",
    "        else: # return the mutation result without hitting any boundary\n",
    "            return offspring+mutation_direction,True\n",
    "    else:\n",
    "        return offspring,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_offspring(feature_num,pool_absorption,mutation_rate,sigma,batch_size):\n",
    "    \"\"\"\n",
    "    To do: generate the next set of experiments according to the current observation\n",
    "    Args:\n",
    "        feature_num: the number of sample features\n",
    "        pool_absorption: the pool recording the information of maximized absorption band: \n",
    "                        [feature,performance,index of attribute]\n",
    "        mutation_rate: the rate for mutation\n",
    "        sigma: the standard deviation of mutation\n",
    "        batch_size: the experiment number for every generation\n",
    "    Returns:\n",
    "        offspring: the generated offspring\n",
    "    \"\"\"\n",
    "    # performance cross_over+mutation\n",
    "    offspring=np.empty((0,feature_num))\n",
    "    while len(offspring)<batch_size/2:\n",
    "        # performance crossover and normalize it to be within the range\n",
    "        offspring_temp_original=cross_over(pool_absorption,feature_num)\n",
    "        # normalize the offsrping_temp_original to the boundary if it's out of boundary (might still be a slightly different)\n",
    "        if offspring_temp_original.sum(axis=1)>1:\n",
    "            offspring_temp_original = offspring_temp_original/offspring_temp_original.sum(axis=1)\n",
    "            \n",
    "            # might be some numerical error\n",
    "            # here we print it to make sure it's small\n",
    "            if offspring_temp_original.sum() != 1: \n",
    "                print(\"offspring_temp_original is not exactly equal to 1\")\n",
    "                print(offspring_temp_original.sum())\n",
    "\n",
    "        # performance mutation and the probabilit of getting mutated is mutation_rate\n",
    "        # if it's near the boundary, the mutation chance would be small because of the limitation of the boundary\n",
    "        print(\"before mutation\")\n",
    "        print(offspring_temp_original)\n",
    "        offspring_temp,mutation_flag=mutation(offspring_temp_original,mutation_rate,sigma)\n",
    "        print(mutation_flag)\n",
    "        print(\"after mutation\")\n",
    "        print(offspring_temp)\n",
    "        # here we check point if the boundary still holds\n",
    "        if sum(abs(offspring_temp[offspring_temp<0])>1e-5)>0:\n",
    "            print(\"Error! The negative value is too large!\")\n",
    "            print(offspring_temp)\n",
    "        # we also need to correct the numerical error after mutation when the float point is smaller than 0\n",
    "        offspring_temp[offspring_temp<0] = 0\n",
    "        \n",
    "        # performance a validate mutation if we decide to mutate so it's different from the original one\n",
    "        # it's to get rid of the trapping problem in the boundary\n",
    "        while (mutation_flag == True) and ((abs(offspring_temp - offspring_temp_original)<1e-10).sum() == feature_num):\n",
    "            offspring_temp,mutation_flag=mutation(offspring_temp_original,1,sigma)\n",
    "            # check point, if the negative value is too large, there's an error\n",
    "            if sum(abs(offspring_temp[offspring_temp<0])>1e-5)>0:\n",
    "                print(\"Error! The negative value is too large!\")\n",
    "                print(offspring_temp)\n",
    "            # correct the numerical error after mutation\n",
    "            offspring_temp[offspring_temp<0] = 0\n",
    "            if mutation_flag == False:\n",
    "                print(\"Error in crossover!\")\n",
    "        # after everything, check if the constrain still holds\n",
    "        # numerical error is acceptable and we try to correct it, but in some time we can't correct\n",
    "        # as long as it's small, it's fine\n",
    "        if offspring_temp.sum(axis=1)>1:\n",
    "            print(\"In crossover, the summation is larger than 1!\")\n",
    "            print(\"Mutation flag: {}\".format(mutation_flag))\n",
    "            print(offspring_temp.sum())\n",
    "            offspring_temp=offspring_temp/offspring_temp.sum()\n",
    "            print(offspring_temp.sum())\n",
    "        \n",
    "        offspring=np.append(offspring,offspring_temp,axis=0)\n",
    "        offspring=np.unique(offspring,axis=0)\n",
    "        \n",
    "    # performance pure mutation\n",
    "    pool=np.array(pool_absorption)[:,0:feature_num]\n",
    "    while len(offspring)<batch_size:\n",
    "        # randomly select one sample for mutation\n",
    "        index=np.random.choice(len(pool),size=1).item()\n",
    "        offspring_temp,mutation_flag=mutation(pool[index],1,sigma)\n",
    "        # check point\n",
    "        if sum(abs(offspring_temp[offspring_temp<0])>1e-5)>0:\n",
    "            print(\"Error! The negative value is too large!\")\n",
    "            print(offspring_temp)\n",
    "        offspring_temp[offspring_temp<0] = 0\n",
    "        # if the mutation doesn't happen in this case, there's an error\n",
    "        if mutation_flag == False:\n",
    "            print(\"Error in mutation!\")\n",
    "        # get rid of the problem when it's in the boundary, \n",
    "        # it has the probabilit of being trapped and didn't really get changed.\n",
    "        while ((abs(offspring_temp - pool[index])<1e-10).sum() == feature_num):\n",
    "            offspring_temp,mutation_flag = mutation(pool[index],1,sigma)\n",
    "            # check point\n",
    "            if sum(abs(offspring_temp[offspring_temp<0])>1e-5)>0:\n",
    "                print(\"Error! The negative value is too large!\")\n",
    "            # get rid of numerical error\n",
    "            offspring_temp[offspring_temp<0] = 0\n",
    "            if mutation_flag == False:\n",
    "                print(\"Error in mutation!\")\n",
    "        # due to numerical error, it's acceptable. But the difference shouldn't be to much\n",
    "        if offspring_temp.sum(axis=1)>1:\n",
    "            print(\"In mutation, the summation is larger than 1!\")\n",
    "            print(\"Mutation flag: {}\".format(mutation_flag))\n",
    "            print(offspring_temp.sum())\n",
    "            offspring_temp=offspring_temp/offspring_temp.sum()\n",
    "            print(offspring_temp.sum())\n",
    "            \n",
    "        offspring=np.append(offspring,offspring_temp,axis=0)\n",
    "        offspring=np.unique(offspring,axis=0)\n",
    "        print(\"In mutation, the original pool[index] is \\n {}\".format(pool[index]))\n",
    "        print(\"After mutation, it's \\n {}\".format(offspring_temp))\n",
    "        print(\"{}\".format(pool[index] - offspring_temp))\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_pool(offspring,offspring_performance,offspring_index,pool_absorption):\n",
    "    \"\"\"\n",
    "    To do: update the current pool with MAP-elite algorithm\n",
    "    Args:\n",
    "        offspring: the offspring \n",
    "        offspring_performance: the main performance from the offspring\n",
    "        offspring_index: the interested attributes from the offspring\n",
    "        pool_absorption: the current pool of samples with high absorption\n",
    "    Returns:\n",
    "        pool_absorption: the updated pool of samples with high absorption\n",
    "    \"\"\"\n",
    "    index=offspring_index\n",
    "    \n",
    "    for attribute_index in np.unique(index):\n",
    "        performance_temp=offspring_performance[index==attribute_index]\n",
    "        offspring_temp=offspring[index==attribute_index]\n",
    "        sample_1_index=np.argmax(performance_temp[:,0])\n",
    "        sample_1=np.concatenate((offspring_temp[sample_1_index],\n",
    "                                 performance_temp[sample_1_index],\n",
    "                                 [attribute_index]))\n",
    "        \n",
    "        if len(pool_absorption[pool_absorption[:,-1]==attribute_index])==0:\n",
    "            pool_absorption=np.vstack((pool_absorption,sample_1))\n",
    "        elif pool_absorption[pool_absorption[:,-1]==attribute_index][0,feature_num]<sample_1[feature_num]:\n",
    "            pool_absorption[pool_absorption[:,-1]==attribute_index]=sample_1.reshape(1,-1)\n",
    "            \n",
    "    return pool_absorption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reagent_volume(X,Ranges,V_total=11.5):\n",
    "    X_new=np.zeros((X.shape))\n",
    "    for i in range(len(Ranges)):\n",
    "        X_new[:,i]=X[:,i]*(Ranges[i][1]-Ranges[i][0])+Ranges[i][0]\n",
    "    X_new=np.around(X_new,2)\n",
    "    X_final=np.hstack((X_new,V_total-X_new.sum(axis=1).reshape(-1,1)))\n",
    "    return np.around(X_final,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_json_file_for_Nanobot(X,Ranges,V_total,generation_num,random_sampling_size=3):\n",
    "    #write out the volume of algorithm X\n",
    "    if generation_num==0:\n",
    "        pass\n",
    "    else:\n",
    "        X_temp=obtain_constrained_random_samples(feature_num=feature_num,initial_num=random_sampling_size)\n",
    "        X=np.vstack((X,X_temp))\n",
    "        \n",
    "    reagents=create_reagent_volume(X,Ranges,V_total)\n",
    "    reagent_dic = {}\n",
    "    \n",
    "    reagents[reagents<=0] = 10**(-10)\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        reagent_dic[\"exp{}\".format(i)]={}\n",
    "        reagent_dic[\"exp{}\".format(i)][\"surfactant\"]=reagents[i][1]\n",
    "        reagent_dic[\"exp{}\".format(i)][\"gold\"]=reagents[i][0]\n",
    "        reagent_dic[\"exp{}\".format(i)][\"silver\"]=reagents[i][2]\n",
    "        reagent_dic[\"exp{}\".format(i)][\"reductant\"]=reagents[i][3]\n",
    "        reagent_dic[\"exp{}\".format(i)][\"water\"]=reagents[i][4]\n",
    "        reagent_dic[\"exp{}\".format(i)][\"seeds\"]=0.5 \n",
    "        \n",
    "#     #add a reference experimental conditions to make sure Nanobot is working fine\n",
    "    reagent_dic[\"exp{}\".format(23)]={}\n",
    "    reagent_dic[\"exp{}\".format(23)][\"surfactant\"]=4.4\n",
    "    reagent_dic[\"exp{}\".format(23)][\"gold\"]=2.5\n",
    "    reagent_dic[\"exp{}\".format(23)][\"silver\"]=1.8\n",
    "    reagent_dic[\"exp{}\".format(23)][\"reductant\"]=1.1\n",
    "    reagent_dic[\"exp{}\".format(23)][\"water\"]=1.8\n",
    "    reagent_dic[\"exp{}\".format(23)][\"seeds\"]=0.5\n",
    "\n",
    "    with open(base_directory+'data%d.json'%generation_num, 'w') as outfile:\n",
    "        json.dump(reagent_dic, outfile)\n",
    "    return reagents,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_Nanobot(X,generation_num):\n",
    "    \"\"\"\n",
    "    read in the processed data except the last sample (because it's a reference sample)\n",
    "    Args:\n",
    "        X: the original X\n",
    "        generation_num: generation number\n",
    "    Returns:\n",
    "        X_new: the duplicated X (corresponding to peak system)\n",
    "        performance: the corresponding performance\n",
    "        index_set: the index\n",
    "        roughenss_set: the roughness of the sample UV-Vis\n",
    "    \"\"\"\n",
    "    data=np.load(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/data_total.npy\",allow_pickle=True)\n",
    "    performance = []\n",
    "    X_new = []\n",
    "    index_set = []\n",
    "    roughness_set = []\n",
    "    prominence_set=[]\n",
    "    if len(X) != 23:\n",
    "        print(\"Possible wrong X size!\")\n",
    "    for i in range(len(X)):\n",
    "        data_temp = data[i]\n",
    "        if len(data_temp) == 0:\n",
    "            print(\"Sample %d has no data\" %i)\n",
    "            pass\n",
    "        else:\n",
    "            if data_temp[0] == 1:\n",
    "                X_new.append(X[i])\n",
    "                performance.append(data_temp[1])\n",
    "                index_set.append(data_temp[2])\n",
    "                roughness_set.append(data_temp[3])\n",
    "                prominence_set.append(data_temp[4])\n",
    "            else:\n",
    "                X_new.append(X[i])\n",
    "                X_new.append(X[i])\n",
    "                performance.append(data_temp[1])\n",
    "                performance.append(data_temp[2])\n",
    "                index_set.append(100+100*data_temp[3][0]+data_temp[3][1])\n",
    "                index_set.append(10000+10000*data_temp[3][0]+data_temp[3][1])\n",
    "                roughness_set.append(data_temp[4])\n",
    "                roughness_set.append(data_temp[4])\n",
    "                prominence_set.append(data_temp[5])\n",
    "                prominence_set.append(data_temp[5])\n",
    "                \n",
    "    return np.array(X_new),np.array(performance).reshape(-1,1),np.array(index_set),np.array(roughness_set),np.array(prominence_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_num=4 # degree of freedoms in this experiment\n",
    "initial_num=23 # the initial random sampling number and here we apply 23 random experiments + 1 reference experiemnts\n",
    "batch_size=20 # the number of mutation+crossover in that generations, \n",
    "            # and we apply 20 normal experiments+ 3 random + 1 reference\n",
    "    \n",
    "mutation_rate=0.4 # the probability that a mutation can happen after cross-over\n",
    "sigma= 0.05 # the sigma of gassuain distribution in the mutation process\n",
    "\n",
    "generation_num=0\n",
    "\n",
    "#first, a random sampling is utilized to generate random samples\n",
    "X=obtain_constrained_random_samples(feature_num=4,initial_num=initial_num)\n",
    "Ranges=[[0,11.5], #Au\n",
    "        [0,11.5], #CTAB\n",
    "        [0,11.5], #Ag\n",
    "        [0,11.5]] #Reductant\n",
    "# then, a json_file is generated according to X and Ranges, constraning the overall volume and given the reference condition\n",
    "reagents,X=generate_json_file_for_Nanobot(X,Ranges,V_total=11.5,generation_num=generation_num,random_sampling_size=3)\n",
    "print(X.sum(axis=1).max())\n",
    "print(X.min())\n",
    "print(X)\n",
    "print(reagents.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunNanobot and get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got the results from Nanobot and analyze them with the UV-Vis spectrum processor\n",
    "input(\"Press Enter to continue after running the platform and analyzing the data ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in the results from spectrum processor\n",
    "X,performance,index,roughness,prominence_set=objective_Nanobot(X,generation_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter bad data\n",
    "good_data_index=(roughness.flatten()<0.005) & (prominence_set>0.2)\n",
    "X=X[good_data_index]\n",
    "performance=performance[good_data_index]\n",
    "index=np.around(index[good_data_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the initial pool\n",
    "pool_absorption=[]\n",
    "#noting both performance are recorded and attached to the pool\n",
    "for attribute_index in np.unique(index):\n",
    "    performance_temp=performance[index==attribute_index]\n",
    "    X_temp=X[index==attribute_index]\n",
    "    \n",
    "    sample_1_index=np.argmax(performance_temp[:,0])\n",
    "    sample_1=np.concatenate((X_temp[sample_1_index],\n",
    "                             performance_temp[sample_1_index],\n",
    "                             [attribute_index]))\n",
    "    pool_absorption.append(sample_1)\n",
    "    \n",
    "pool_absorption=np.array(pool_absorption)\n",
    "\n",
    "np.savez(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption%d\"%generation_num,pool_absorption)\n",
    "\n",
    "generation_num=generation_num+1\n",
    "\n",
    "print(len(pool_absorption))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the main part to run the platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loop in range(9):\n",
    "    #generate offspring according to the current pool\n",
    "    offspring=generate_offspring(feature_num,pool_absorption,mutation_rate,sigma,batch_size)\n",
    "    reagents,X=generate_json_file_for_Nanobot(offspring,Ranges,V_total=11.5,generation_num=generation_num)\n",
    "    offspring=X\n",
    "    print(X.sum(axis=1))\n",
    "    print(X)\n",
    "    print(reagents.min())\n",
    "    print(reagents.sum(axis=1))\n",
    "    \n",
    "    # Run nanobot and get the data\n",
    "    input(\"Press Enter to continue after running the platform and analyzing the data ...\")\n",
    "    \n",
    "    #read in the current offspring results\n",
    "    offspring,offspring_performance,offspring_index,roughness,prominence_set=objective_Nanobot(offspring,generation_num)\n",
    "\n",
    "    #filter bad data\n",
    "    good_data_index = (roughness.flatten()<0.005) & (prominence_set>0.2)\n",
    "\n",
    "    offspring=offspring[good_data_index]\n",
    "    offspring_performance=offspring_performance[good_data_index]\n",
    "    offspring_index=np.around(offspring_index[good_data_index])\n",
    "    #update the pool\n",
    "    pool_absorption=update_pool(offspring,offspring_performance,offspring_index,pool_absorption)\n",
    "    print(generation_num)\n",
    "    print(pool_absorption)\n",
    "    np.savez(base_directory+\"MAP_elite_generation_%d\"%generation_num+\"/pool_absorption%d\"%generation_num,pool_absorption)\n",
    "\n",
    "    generation_num=generation_num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
