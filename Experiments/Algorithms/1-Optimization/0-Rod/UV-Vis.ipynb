{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import find_peaks, peak_widths,peak_prominences\n",
    "import bisect\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def low_pass_filter(wavelengths,intensities,fc=15):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Use a low pass filter to deal with the read_in data.\n",
    "    Args:\n",
    "        wavelengths: the input wavelength.\n",
    "        intensities: the corresponding intensities of UV-Vis.\n",
    "        fc: frequency of low pass filter.\n",
    "    Returns:\n",
    "        series: the intensities passing through the low-pass filter.\n",
    "    \"\"\"\n",
    "    fs = wavelengths.shape[0]  # Sampling frequency\n",
    "    w = fc / (fs / 2) # Normalize the frequency\n",
    "    b, a = signal.butter(5, w, 'low')\n",
    "    series = signal.filtfilt(b, a, intensities)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_prominence(x,a=1,b=70,c=0.4,d=100,e=1,f=0.1,threshold=0.05):\n",
    "    \"\"\"\n",
    "    To do: \n",
    "        Definte a function which is more sensitive when x is small.\n",
    "    Args:\n",
    "        x: the peak prominence to be processed by this function.\n",
    "        a,b,c,d,e,f: constant the tune the shape of this function.\n",
    "        threshold: the threshold from where this function begin to behave like a linear function.\n",
    "    Returns:\n",
    "        The processed peak prominence after this function, which will be further used to calculate the scores.\n",
    "    \"\"\"\n",
    "    if x<threshold:\n",
    "        return (np.tanh((x-threshold)*d)+e)*f\n",
    "    else:\n",
    "        return (a*x+c*(1/(1+np.exp(-b*x))-0.5))/(a+c*(1/(1+np.exp(-b))-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def peak_binary(x,b=100,threshold=0.05):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Use a tanh function to binarize peaks accoridng to its promiencen.\n",
    "    Args:\n",
    "        x: the peak prominence to be processed by this function.\n",
    "        b: a variable to tune the shape of this function.\n",
    "        threshold: the threshold after which the function behave like a linear function.\n",
    "    Returns:\n",
    "        the processed peak prominence.\n",
    "    \"\"\"\n",
    "    return (np.tanh((x-threshold)*b)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalizedata(series_original):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Definte a function which normalize the input data into range (0,1).\n",
    "        \n",
    "    \"\"\"\n",
    "    return (series_original-np.min(series_original))/(np.max(series_original)-np.min(series_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calcualte_smoothness(x):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Calculate the smootheness of the spectrum. \n",
    "        The smoothness is defined byy the absolute difference between the original spectrum and the spectrum after low-pass filter.\n",
    "    Args:\n",
    "        x: the UV-Vis spectrum\n",
    "    Returns:\n",
    "        The quantity measuring the smootheness of this spectrum.\n",
    "    \"\"\"\n",
    "    return np.std(np.diff(x))/abs(np.mean(np.diff(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_in_UV_Vis(base_sample,index,lower=400,upper=950,fc=15,color=\"red\",plot_flag=True,normalize=False):\n",
    "    #Read in json file\n",
    "    with open(base_sample+f\"00%02d/uv.json\"%(index)) as json_data:\n",
    "        d = json.load(json_data)\n",
    "        #read wavelength and intensities\n",
    "        wavelengths = np.array(d['wavelength'])\n",
    "        series_original = np.array(d['absorbances'])\n",
    "    #trim data\n",
    "    series_original = series_original[(wavelengths>lower) & (wavelengths < upper)]\n",
    "    wavelengths = wavelengths[(wavelengths>lower) & (wavelengths < upper)]\n",
    "    #trim data in the range of lower to upper\n",
    "    series_original=normalizedata(series_original[(wavelengths>lower) & (wavelengths < upper)])\n",
    "    series=low_pass_filter(wavelengths,series_original,fc=fc)\n",
    "    roughness=abs(series-series_original).mean()\n",
    "    \n",
    "    series=normalizedata(series)\n",
    "    \n",
    "    if plot_flag and normalize==True:\n",
    "        plt.plot(wavelengths,series,c=\"black\")\n",
    "        plt.plot(wavelengths,series_original,c=color)\n",
    "    \n",
    "    UV_inter = interp1d(wavelengths, series, kind='cubic',fill_value='extrapolate' )\n",
    "    return UV_inter,roughness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_1D(region,boundary,roughness,series,peaks,prominences,wavelengths):    \n",
    "    #plot part\n",
    "    plt.figure()\n",
    "        \n",
    "    plt.plot(wavelengths,series)\n",
    "    plt.plot(wavelengths[peaks], series[peaks], \"x\")\n",
    "    plt.vlines(boundary, ymin=0, ymax=1,color=\"r\",linestyles =\"dashed\")\n",
    "    for region_temp in region:\n",
    "        plt.vlines(region, ymin=0, ymax=1,color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_scores(base_sample,index,lower=400,upper=950,num=1101,False_width=10000,plot_flag=True):\n",
    "    \"\"\"\n",
    "    To do:\n",
    "        Calculate the defined UV-Vis scores of a sample.\n",
    "    Args:\n",
    "        base_sample: the directory of the sample\n",
    "        index: the index of the sample\n",
    "        boundary1: the boundaries to diecretize the UV-Vis region for one peak system\n",
    "        boundary2: the boundaries to discretize the UV-Vis spectrum for two peak system\n",
    "        near_width: the width to define the nearby region\n",
    "        lower: the lower wavelength boundary of UV-Vis\n",
    "        upper: the upper wavelength boundary of UV-Vis\n",
    "        num: the sampling number in wavelength [lower,upper]\n",
    "        False_width: the width this function returns when there's no peak in the system\n",
    "    Returns:\n",
    "        \n",
    "   \"\"\"\n",
    "    UV_sample,roughness=read_in_UV_Vis(base_sample,index,plot_flag=plot_flag)\n",
    "    #define the wavelength and got the UV-Vis spectrum\n",
    "    wavelengths=np.linspace(lower,upper,num)\n",
    "    series=UV_sample(wavelengths)\n",
    "\n",
    "    #find peaks in the data\n",
    "    peaks, _ = find_peaks(series,prominence=0.02)\n",
    "    if len(peaks) == 0 or roughness >= 0.005:\n",
    "        print(\"None peaks are found!\")\n",
    "        plt.close()\n",
    "        return []\n",
    "    \n",
    "    #find prominence of individual peaks\n",
    "    prominences = peak_prominences(series, peaks)[0]\n",
    "    if max(prominences) <=0.2:\n",
    "        return []\n",
    "    \n",
    "    results_half = peak_widths(series, peaks, rel_height=0.5)\n",
    "    results_full = peak_widths(series, peaks, rel_height=1)\n",
    "    peak_index = prominences.argsort()[-2:][::-1]\n",
    "    peak_positions = []\n",
    "    peak_width = []\n",
    "    peak_intensity = []\n",
    "    \n",
    "    for i in range(len(peak_index)): \n",
    "        peak_positions.append(wavelengths[peaks[peak_index[i]]])\n",
    "        # get the peak width\n",
    "        width = results_half[0][peak_index[i]].item()*(wavelengths[1]-wavelengths[0])\n",
    "        peak_width.append(width)\n",
    "        peak_intensity.append(series[peaks[peak_index[i]]])\n",
    "        \n",
    "    # plot\n",
    "    contour_heights = series[peaks] - prominences\n",
    "    plt.plot(wavelengths,series,'black')\n",
    "    plt.plot(wavelengths[peaks], series[peaks], \"x\")\n",
    "    plt.plot(wavelengths,series_target,'blue')\n",
    "    plt.scatter(wavelengths[_['left_bases']],series[_['left_bases']],c='black')\n",
    "    plt.scatter(wavelengths[_['right_bases']],series[_['right_bases']],c='black')\n",
    "    plt.vlines(x=wavelengths[peaks], ymin=contour_heights, ymax=series[peaks])\n",
    "    plt.hlines(*(results_half[1],wavelengths[np.around(results_half[2]).astype(\"int\")],wavelengths[np.around(results_half[3]).astype(\"int\")]), color=\"C2\")\n",
    "    plt.hlines(*(results_full[1],wavelengths[np.around(results_full[2]).astype(\"int\")],wavelengths[np.around(results_full[3]).astype(\"int\")]), color=\"C3\")\n",
    "    \n",
    "    #return the results\n",
    "    return [peak_intensity,peak_positions,peak_width,series]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the ideal UV-Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get the optimal UV-Vis\n",
    "pathlib.Path('./Optimization_generation_0').mkdir(parents=True, exist_ok=True)\n",
    "optimal_UV = np.loadtxt(\"11_by_33nm_rods.csv\",delimiter = \",\")\n",
    "optimal_UV = normalizedata(optimal_UV)\n",
    "wavelength_temp = np.linspace(400,950,56)\n",
    "UV_sample = interp1d(wavelength_temp, optimal_UV, kind='cubic',fill_value='extrapolate')\n",
    "wavelengths = np.linspace(400,950,1101)\n",
    "\n",
    "series=UV_sample(wavelengths)\n",
    "series_target = np.zeros(series.shape)\n",
    "series_target[:] = series.flatten()\n",
    "#find peaks in the data\n",
    "peaks, _ = find_peaks(series,prominence=0.02)\n",
    "#find prominence of individual peaks\n",
    "prominences = peak_prominences(series, peaks)[0]\n",
    "results_half = peak_widths(series, peaks, rel_height=0.5)\n",
    "results_full = peak_widths(series, peaks, rel_height=1)\n",
    "peak_index = prominences.argsort()[-2:][::-1]\n",
    "peak_positions = []\n",
    "peak_width = []\n",
    "peak_intensity = [] \n",
    "\n",
    "for i in range(len(peak_index)): \n",
    "    peak_positions.append(wavelengths[peaks[peak_index[i]]])\n",
    "    # get the peak width\n",
    "    width = results_half[0][peak_index[i]].item()*(wavelengths[1]-wavelengths[0])\n",
    "    peak_width.append(width)\n",
    "    peak_intensity.append(series[peaks[peak_index[i]]])\n",
    "    \n",
    "#plot \n",
    "plt.plot(wavelengths,series,'black')\n",
    "plt.plot(wavelengths[peaks], series[peaks], \"x\")\n",
    "contour_heights = series[peaks] - prominences\n",
    "plt.scatter(wavelengths[_['left_bases']],series[_['left_bases']],c='black')\n",
    "plt.scatter(wavelengths[_['right_bases']],series[_['right_bases']],c='black')\n",
    "plt.vlines(x=wavelengths[peaks], ymin=contour_heights, ymax=series[peaks])\n",
    "plt.hlines(*(results_half[1],wavelengths[np.around(results_half[2]).astype(\"int\")],wavelengths[np.around(results_half[3]).astype(\"int\")]), color=\"C2\")\n",
    "plt.hlines(*(results_full[1],wavelengths[np.around(results_full[2]).astype(\"int\")],wavelengths[np.around(results_full[3]).astype(\"int\")]), color=\"C3\")\n",
    "plt.show()\n",
    "optimial_data_set = np.array([peak_intensity,peak_positions,peak_width])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the score with the reference UV-Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_space = []\n",
    "output_space = []\n",
    "index_total = []\n",
    "for generation_num in range(10):\n",
    "    plt.figure()\n",
    "    # Path to exploring the first chemical space\n",
    "    base_sample=\"../../0-Exploration/0-Chemical_Space_1/0/MAP_elite_generation_%d//\"%generation_num\n",
    "    total_sample_num = 23\n",
    "    for j in range(total_sample_num):\n",
    "        data_temp = obtain_scores(base_sample,j,lower=400,upper=950,num=1101,False_width=10000,plot_flag=False)\n",
    "        if len(data_temp)>0:\n",
    "            loss = abs(wavelengths[np.argmax(series_target)]-data_temp[1][0])+0.20*(abs(data_temp[3] - series_target).sum())\n",
    "        else:\n",
    "            loss = 100000\n",
    "        output_space.append(loss)\n",
    "        plt.title(loss)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        with open(base_sample+'%04d'%j+\"/params.json\") as json_file:\n",
    "            data_input = json.load(json_file)\n",
    "        print(data_input)        \n",
    "        input_temp = np.array([data_input['gold']/11.5,\n",
    "                               data_input['surfactant']/11.5,\n",
    "                               data_input['silver']/11.5,\n",
    "                               data_input['reductant']/11.5])\n",
    "        input_space.append(input_temp)\n",
    "        index_total.append([generation_num,j,0])\n",
    "        \n",
    "for generation_num in range(1,5):\n",
    "    plt.figure()\n",
    "    base_sample=\"../../0-Exploration/0-Chemical_Space_1/1//MAP_elite_generation_%d//\"%generation_num\n",
    "    total_sample_num = 23\n",
    "    for j in range(total_sample_num):\n",
    "        data_temp = obtain_scores(base_sample,j,lower=400,upper=950,num=1101,False_width=10000,plot_flag=False)\n",
    "        if len(data_temp)>0:\n",
    "            loss = abs(wavelengths[np.argmax(series_target)]-data_temp[1][0])  + 0.20*(abs(data_temp[3] - series_target).sum())\n",
    "        else:\n",
    "            loss = 100000\n",
    "        output_space.append(loss)\n",
    "        plt.title(loss)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        with open(base_sample+'%04d'%j+\"/params.json\") as json_file:\n",
    "            data_input = json.load(json_file)\n",
    "        print(data_input)        \n",
    "        input_temp = np.array([data_input['gold']/11.5,\n",
    "                               data_input['surfactant']/11.5,\n",
    "                               data_input['silver']/11.5,\n",
    "                               data_input['reductant']/11.5])\n",
    "        input_space.append(input_temp)\n",
    "        index_total.append([generation_num,j,1])\n",
    "        \n",
    "for generation_num in range(1,3):\n",
    "    plt.figure()\n",
    "    base_sample=\"../../0-Exploration/0-Chemical_Space_1/2//MAP_elite_generation_%d//\"%generation_num\n",
    "    total_sample_num = 23\n",
    "    for j in range(total_sample_num):\n",
    "        data_temp = obtain_scores(base_sample,j,lower=400,upper=950,num=1101,False_width=10000,plot_flag=False)\n",
    "        if len(data_temp)>0:\n",
    "            loss = abs(wavelengths[np.argmax(series_target)]-data_temp[1][0])  + 0.20*(abs(data_temp[3] - series_target).sum())\n",
    "        else:\n",
    "            loss = 100000\n",
    "        output_space.append(loss)\n",
    "        plt.title(loss)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        with open(base_sample+'%04d'%j+\"/params.json\") as json_file:\n",
    "            data_input = json.load(json_file)\n",
    "        print(data_input)        \n",
    "        input_temp = np.array([data_input['gold']/11.5,\n",
    "                               data_input['surfactant']/11.5,\n",
    "                               data_input['silver']/11.5,\n",
    "                               data_input['reductant']/11.5])\n",
    "        input_space.append(input_temp)\n",
    "        index_total.append([generation_num,j,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_space = np.array(output_space)\n",
    "input_space = np.array(input_space)\n",
    "index_total = np.array(index_total)\n",
    "np.savetxt('output_space.csv',output_space,delimiter=',')\n",
    "np.savetxt('input_space.csv',input_space,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the initial data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_space = np.loadtxt('output_space.csv',delimiter=',')\n",
    "input_space = np.loadtxt('input_space.csv',delimiter=',')\n",
    "index_total = np.array(index_total)\n",
    "fintess_raw = -output_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_space = input_space[fintess_raw>-100000]\n",
    "index_total_eff = index_total[fintess_raw>-100000]\n",
    "fintess_raw = fintess_raw[fintess_raw>-100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nearest_N = 10\n",
    "fitness = []\n",
    "novelty_total = []\n",
    "for i in range(len(fintess_raw)):\n",
    "    novelty = (np.sort(np.sqrt(((np.unique(input_space,axis=0) - input_space[i])**2).sum(axis=1)))[0:nearest_N]).mean()\n",
    "    fitness_temp =  100*novelty + fintess_raw[i]\n",
    "    fitness.append(fitness_temp)\n",
    "    novelty_total.append(novelty)\n",
    "fitness = np.array(fitness)\n",
    "novelty_total = np.array(novelty_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(novelty_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Process data for every generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for generation_num in range(1,6):\n",
    "    input(\"Press Enter to continue after running the platform and acquiring the data ...\")\n",
    "    input_space = []\n",
    "    output_space = []\n",
    "    base_sample=\"./Optimization_generation_%d//\"%generation_num\n",
    "    total_sample_num = 23\n",
    "    for j in range(total_sample_num):\n",
    "        plt.figure()\n",
    "        data_temp = obtain_scores(base_sample,j,lower=400,upper=950,num=1101,False_width=10000,plot_flag=False)\n",
    "        if len(data_temp)>0:\n",
    "            loss = abs(wavelengths[np.argmax(series_target)]-data_temp[1][0])+0.20*(abs(data_temp[3] - series_target).sum())\n",
    "        else:\n",
    "            loss = 100000\n",
    "        output_space.append(loss)\n",
    "        plt.title(loss)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        with open(base_sample+'%04d'%j+\"/params.json\") as json_file:\n",
    "            data_input = json.load(json_file)\n",
    "        print(data_input)        \n",
    "        input_temp = np.array([data_input['gold']/11.5,\n",
    "                               data_input['surfactant']/11.5,\n",
    "                               data_input['silver']/11.5,\n",
    "                               data_input['reductant']/11.5])\n",
    "        input_space.append(input_temp)\n",
    "\n",
    "\n",
    "    np.savetxt(base_sample+'input_space.csv',input_space,delimiter=',')\n",
    "    np.savetxt(base_sample+'output_space.csv',output_space,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the optimized solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_space = list(np.loadtxt('output_space.csv',delimiter=','))\n",
    "input_space = list(np.loadtxt('input_space.csv',delimiter=','))\n",
    "\n",
    "for generation_num in range(1,6):\n",
    "    base_sample=\"./Optimization_generation_%d//\"%generation_num\n",
    "    total_sample_num = 23\n",
    "    for j in range(total_sample_num):\n",
    "        plt.figure()\n",
    "        data_temp = obtain_scores(base_sample,j,lower=400,upper=950,num=1101,False_width=10000,plot_flag=False)\n",
    "        if len(data_temp)>0:\n",
    "            loss = abs(wavelengths[np.argmax(series_target)]-data_temp[1][0])+0.20*(abs(data_temp[3] - series_target).sum())\n",
    "        else:\n",
    "            loss = 100000\n",
    "        output_space.append(loss)\n",
    "        plt.title(loss)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        with open(base_sample+'%04d'%j+\"/params.json\") as json_file:\n",
    "            data_input = json.load(json_file)     \n",
    "        input_temp = np.array([data_input['gold']/11.5,\n",
    "                               data_input['surfactant']/11.5,\n",
    "                               data_input['silver']/11.5,\n",
    "                               data_input['reductant']/11.5])\n",
    "        input_space.append(input_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_space = np.array(input_space)\n",
    "output_space = np.array(output_space)\n",
    "fintess_raw = -output_space\n",
    "input_space = input_space[fintess_raw>-100000]\n",
    "fintess_raw = fintess_raw[fintess_raw>-100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_space = input_space[np.argsort(-fintess_raw)]\n",
    "fintess_raw = fintess_raw[np.argsort(-fintess_raw)]\n",
    "u, indices = np.unique(input_space, axis=0,return_index=True)\n",
    "input_space_final = input_space[np.sort(indices)]\n",
    "fintess_raw_final = fintess_raw[np.sort(indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(input_space_final)):\n",
    "    if (fintess_raw_final[i]>=fintess_raw_final[np.argsort(np.sqrt(((input_space_final[i] - input_space_final)**2).sum(axis=1)))[0:6]]).sum()==6:\n",
    "        print(i)\n",
    "        print(input_space_final[i]*11.5)\n",
    "        print(fintess_raw_final[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
